<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>我是山姆鍋</title>
  
  <subtitle>軟體開發方法、技術與工具的應用紀錄。</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://samkuo.me/"/>
  <updated>2020-06-07T01:35:01.042Z</updated>
  <id>https://samkuo.me/</id>
  
  <author>
    <name>Sampot (山姆鍋)</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>我的 K8S DevOps 實驗環境 - 控制平面端點</title>
    <link href="https://samkuo.me/post/2020/06/my-k8s-devops-lab-control-plane-endpoint/"/>
    <id>https://samkuo.me/post/2020/06/my-k8s-devops-lab-control-plane-endpoint/</id>
    <published>2020-06-05T09:49:25.000Z</published>
    <updated>2020-06-07T01:35:01.042Z</updated>
    
    <content type="html"><![CDATA[<p>本文延續「<a href="/post/2020/05/my-k8s-devops-lab-env/" title="我的 K8S DevOps 實驗環境 - 基礎篇">我的 K8S DevOps 實驗環境 - 基礎篇</a>」，針對其中的控制平面端點 (control-plane endpoint) 加以說明。作為高可用 K8S 叢集的必要元件，控制平面端點需要負責提供 API 服務的負載均衡 (load balancing) 以及錯誤轉移 (failover) 機制，山姆鍋藉由 HAProxy 以及 Keepalived 來實現控制平面端點。</p><a id="more"></a><h2 id="K8S-控制平面元件">K8S 控制平面元件</h2><p>工作負載 (workload) 的高可用 (high availability) 由 K8S 負責提供，所以，高可用 K8S 叢集主要在確保 K8S 控制平面元件的冗余，也就是確保服務 (e.g. API server) 可以容錯，使得叢集內的排程工作持續順利進行。</p><hr><p><em>下圖由 Kubernetes 官方文件所提供，這裡主要目的在於展示控制平面元件。</em></p><div class="figure " style="width:;"><img class="fig-img" src="https://d33wubrfki0l68.cloudfront.net/7016517375d10c702489167e704dcb99e570df85/7bb53/images/docs/components-of-kubernetes.png" alt=""></div><p>下面各小節簡介控制平面元件以及說明該元件採用的高可用模式。</p><h3 id="API-Server">API Server</h3><p>提供 K8S 的 API 服務，屬於無狀態 (stateless) 元件，所以，叢集中的每個 API Server 實例 (instance) 都可以提供服務。本文所謂的「控制平面端點」就是為了隱藏 API Server 實例的故障以及將請求分散給不同的實例來均衡負載。</p><h2 id="Kube-Controller-Manager">Kube Controller Manager</h2><p>Controller 負責確保叢集內某類特定資源的狀態與 API Server 回傳的狀態一致，Controller Manager 提供這些 controller 的執行支援。Controller Manager 的高可用採用 leader-followers 模式，同一時間只有作為 leader 的 Controller Manager 實際在運作，其餘實例在現任 leader 故障時重新選舉新 leader 接替。</p><h2 id="Scheduler">Scheduler</h2><p>負責叢集中工作負載的主要排程服務，例如，決定 Pod 要配置到哪個節點。同一時間只有一個 Scheduler 在負責排程工作，其餘實例作為熱備援 (hot standby) 可以隨時接替工作。</p><h2 id="Etcd">Etcd</h2><p>分散式資料存儲，叢集內的資源資料與狀態都存放在此。由於 Etcd 的元件內部使用 <a href="https://zh.wikipedia.org/wiki/Raft" target="_blank" rel="noopener">Raft</a> 共識演算法，元件分別扮演 leader 或者 follower 角色。Etcd 叢集寫入 (write) 操作都由 leader 元件接受並將結果複製到叢集中的所有 follower 元件。由於 leader 選舉採用多數決 (quorum)，因此，Etcd 叢集需由奇數個實例組成 (至少 3 個，生產環境建議為 5 個)。 Etcd 叢集可以選擇部署在與其它 K8S 控制元件分開的節點，但此實驗環境選擇較簡單的架構，每一台控制節點 (master/control-plane node) 都部署上述元件的實例。</p><blockquote><p>雖然此實驗環境使用 Etcd 作為叢集高可用資料存儲，但不同的 K8S 發行版本可能採用別的方案。例如，K3S 也可以支援 MySQL/PostgreSQL 作為資料存儲。</p></blockquote><h2 id="控制平面端點">控制平面端點</h2><p>從架構圖可以得知，多數 K8S 的控制平面元件，包括 Kubelet 守護行程 (daemon) 以及客戶端程式等都需要呼叫 API Server。由於有多個 API Server 實例，需要提供一個統一固定的存取點來簡化 K8S API 客戶端呼叫 (e.g. kubelet 只能設定一個 API server 端點) 以及隱藏故障移轉過程的影響。傳統上，對於一組提供相同服務的守護行程 (daemons) 都是透過服務負載均衡器 (server loadbalancer) 來分散請求到不同副本 (replica)。有了服務負載均衡器雖然可以增加服務請求的數量以及效率，但如果負載均衡器故障則會影響到客戶端。所以，常利用虛擬 IP 來讓兩個以上的負載均衡器可以互相備援。</p><p>此實驗環境分別採用 Keepalived 來實現虛擬 IP 位址，以及透過 HAProxy 來提供 API 服務的負載均衡。從山姆鍋開始研究 Linux HA 開始，這個組合就是常常出現的方案且是經得起時間考驗的。</p><h3 id="Keepalived-安裝設定">Keepalived 安裝設定</h3><p>透過 <a href="https://zh.wikipedia.org/wiki/%E5%9C%B0%E5%9D%80%E8%A7%A3%E6%9E%90%E5%8D%8F%E8%AE%AE" target="_blank" rel="noopener">ARP</a> 協定，節點可以廣播所屬網卡的 IP 位址讓其它節點可以找到 IP 所對應的網卡硬體位址 (MAC Address) 以完成封包的路由 (routing)。根據服務節點的健康狀態，可以選擇性地由不同節點來廣播 ARP 封包從而實現虛擬 IP 的錯誤移轉。Keepalived 作為支援 <a href="https://zh.wikipedia.org/wiki/%E8%99%9B%E6%93%AC%E8%B7%AF%E7%94%B1%E5%99%A8%E5%82%99%E6%8F%B4%E5%8D%94%E5%AE%9A" target="_blank" rel="noopener">VRRP</a> 的 Linux 高可用元件，除了可以實現前述的虛擬 IP 功能外，當發生錯誤轉移時可以呼叫自訂的腳本。這點對於無法在網卡層面支援虛擬 IP 的環境 (如 DigitalOcean 等雲端服務)，但支援 API 來動態綁定浮動 (floating) IP 的情境可以達成與虛擬 IP 相同的目的。因此，在機房或者雲端自建 K8S 叢集都有機會可以使用 HAProxy + Keepalived 來實現高可用的負載均衡服務。但即使如此，除非有特別考量，山姆鍋還是傾向於使用雲端託管的 K8S 服務的。</p><blockquote><p>如果只是為了高可用，其實可以只使用 Keepalived 來提供。基於此實驗環境目標之一是盡可能接近生產環境設定，所以也採用負載均衡器以充分利用系統效能。</p></blockquote><p>Keepalived 以系統套件安裝並以守護行程 (daemon) 方式執行：</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apt-get install -y keepalived</span><br></pre></td></tr></tbody></table></figure><p>下面是 /etc/keepalived/keepalived.conf 設定檔內容樣板 (template)：</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">global_defs {</span><br><span class="line">  default_interface <span class="variable">${SPK_KEEPALIVED_INTERFACE}</span></span><br><span class="line">}</span><br><span class="line">vrrp_instance VI_1 {</span><br><span class="line">    interface <span class="variable">${SPK_KEEPALIVED_INTERFACE}</span></span><br><span class="line">    virtual_router_id 101</span><br><span class="line">    nopreempt</span><br><span class="line">    advert_int 1</span><br><span class="line">    authentication {</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass 1111</span><br><span class="line">    }</span><br><span class="line">    unicast_src_ip <span class="variable">${API_ADV_ADDRESS}</span></span><br><span class="line">    unicast_peer {</span><br><span class="line">      <span class="variable">${SPK_LAB_NETWORK}</span>.11</span><br><span class="line">      <span class="variable">${SPK_LAB_NETWORK}</span>.12</span><br><span class="line">      <span class="variable">${SPK_LAB_NETWORK}</span>.13</span><br><span class="line">    }</span><br><span class="line">    virtual_ipaddress {</span><br><span class="line">        <span class="variable">${SPK_KEEPALIVED_VIRTUAL_IP}</span></span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>其中，</p><ul><li><p>${SPK_KEEPALIVED_INTERFACE}: 是虛擬 IP 預計綁定的網卡。由於 Vagrant 設定的虛擬機中，第一張網卡是 NAT 模式，此實驗環境使用第二張網卡作為叢集內節點的通訊用途，第二張網卡的預設名稱是 <code>eth1</code>。</p></li><li><p>${API_ADV_ADDRESS}: 此 IP 位址就是 Keepalived 實例所在的控制節點 IP 位址。</p></li><li><p>${SPK_KEEPALIVED_VIRTUAL_IP}：此變數就是 API 服務的虛擬 IP 位址，預設是 <code>172.42.42.10</code>。</p></li><li><p>${SPK_LAB_NETWORK}.11 ~ .13: 基於雲端環境多數不支援 IP Multicast 的假設下，Keepalived 透過 unicast 來進行對等點 (peer) 偵測工作。</p></li></ul><blockquote><p>注意: Keepalived 設定 <code>nopreempt</code>，且沒有設定 <code>priority</code>(所以每個實例優先權相同)。這樣做的目的是為了避免較高優先權的 keepalived 恢復後將 IP 轉移回去 (failback)，造成現有的 TCP 連線中斷。</p></blockquote><p>設定修改完成後，重啟 Keepalived 守護行程：</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart keepalived</span><br></pre></td></tr></tbody></table></figure><h3 id="HAProxy-安裝設定">HAProxy 安裝設定</h3><p>由於 API Server 的負載均衡只需要依賴 IP 跟 Port，所以只需要可以支援 TCP (layer 4) 的負載均衡器即可。常用的選項是 HAProxy 以及 Nginx，此實驗環境選用 HAProxy 來作為 API Server 的負載均衡器。</p><p>HAProxy 同樣使用系統套件安裝：</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apt-get install -y haproxy</span><br></pre></td></tr></tbody></table></figure><p>底下為 HAProxy 的 <code>/etc/haproxy/haproxy.cfg</code> 設定檔樣板：</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">global</span><br><span class="line">        <span class="built_in">log</span> /dev/<span class="built_in">log</span>    local0</span><br><span class="line">        <span class="built_in">log</span> /dev/<span class="built_in">log</span>    local1 notice</span><br><span class="line">        chroot /var/lib/haproxy</span><br><span class="line">        stats socket /run/haproxy/admin.sock mode 660 level admin expose-fd listeners</span><br><span class="line">        stats timeout 30s</span><br><span class="line">        user haproxy</span><br><span class="line">        group haproxy</span><br><span class="line">        daemon</span><br><span class="line">        ca-base /etc/ssl/certs</span><br><span class="line">        crt-base /etc/ssl/private</span><br><span class="line">frontend spk-frontend</span><br><span class="line">        <span class="built_in">bind</span> *:16443</span><br><span class="line">        mode tcp</span><br><span class="line">        <span class="built_in">log</span> global</span><br><span class="line">        option tcplog</span><br><span class="line">        timeout client 3600s</span><br><span class="line">        backlog 4096</span><br><span class="line">        maxconn 50000</span><br><span class="line">        use_backend spk-masters</span><br><span class="line">backend spk-masters</span><br><span class="line">        mode  tcp</span><br><span class="line">        option redispatch</span><br><span class="line">        balance roundrobin</span><br><span class="line">        timeout connect 1s</span><br><span class="line">        timeout queue 5s</span><br><span class="line">        timeout server 3600s</span><br><span class="line">        server spkmaster-1 <span class="variable">${SPK_LAB_NETWORK}</span>.11:6443 check</span><br><span class="line">        server spkmaster-2 <span class="variable">${SPK_LAB_NETWORK}</span>.12:6443 check</span><br><span class="line">        server spkmaster-3 <span class="variable">${SPK_LAB_NETWORK}</span>.13:6443 check</span><br></pre></td></tr></tbody></table></figure><p>其中，</p><ol><li>此實驗環境的控制平面端點採用 16443 port，而個別 API Server 則是使用 6443 port。</li><li>${SPK_LAB_NETWORK}: 實驗環境網段位址前置字串，預設是 <code>172.42.42</code>。</li><li>可以看出 3 個控制節點的 API Server 端點是寫死的。</li></ol><p>設定修改完成後，重啟 HAProxy 守護行程：</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart haproxy</span><br></pre></td></tr></tbody></table></figure><h2 id="小結">小結</h2><p>在網路上有看過利用 Kubelet 以靜態 Pod 形式執行 HAProxy 以及 Keepalived 的參考文件。但此實驗環境使用的 kubeadm 版本在執行 <code>kubeadm init</code> 或者 <code>kubeadm join</code> 之前，kubelet 並不會正常執行。由於控制平面端點在 <code>kubeadm init</code> 執行前就要正常啟動，這導致無法利用靜態 Pod 形式來部署。另一個替代方式是以 Docker 容器來執行 HAProxy 以及 Keepalived, 也許之後的版本會改採用這種方式。</p><h2 id="參考文章">參考文章</h2><ul><li><a href="https://k2r2bai.com/2019/09/20/ironman2020/day05/" target="_blank" rel="noopener">實現 Kubernetes 高可靠架構部署</a>: 這篇文章使用靜態 Pod 方式來執行 HAProxy 以及 Keepalived。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文延續「&lt;a href=&quot;/post/2020/05/my-k8s-devops-lab-env/&quot; title=&quot;我的 K8S DevOps 實驗環境 - 基礎篇&quot;&gt;我的 K8S DevOps 實驗環境 - 基礎篇&lt;/a&gt;」，針對其中的控制平面端點(control-plane endpoint)加以說明。作為高可用 K8S 叢集的必要元件，控制平面端點需要負責提供 API 服務的負載均衡(load balancing)以及錯誤轉移(failover)機制，山姆鍋藉由 HAProxy 以及 Keepalived 來實現控制平面端點。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Kubernetes" scheme="https://samkuo.me/tag/kubernetes/"/>
    
      <category term="DevOps" scheme="https://samkuo.me/tag/devops/"/>
    
      <category term="SPK Cluster" scheme="https://samkuo.me/tag/spk-cluster/"/>
    
      <category term="High Availability" scheme="https://samkuo.me/tag/high-availability/"/>
    
      <category term="Linux HA" scheme="https://samkuo.me/tag/linux-ha/"/>
    
  </entry>
  
  <entry>
    <title>我的 K8S DevOps 實驗環境 - 基礎篇</title>
    <link href="https://samkuo.me/post/2020/05/my-k8s-devops-lab-env/"/>
    <id>https://samkuo.me/post/2020/05/my-k8s-devops-lab-env/</id>
    <published>2020-05-30T11:58:09.840Z</published>
    <updated>2020-05-31T01:53:33.284Z</updated>
    
    <content type="html"><![CDATA[<p>雖然 Minikube、K3D 或者 Docker for Desktop 都提供 Kubernetes 測試環境可以方便開發雲原生應用軟體。但從運維角度來說，這些工具並不適合用來測試與驗證需要多節點的方案，例如：高可用的 etcd；K8S 的儲存方案如 <a href="https://openebs.io/" target="_blank" rel="noopener">OpenEBS</a>, <a href="https://rook.io/" target="_blank" rel="noopener">ROOK</a> 等需要額外的儲存媒體 (e.g. 硬碟) 來實現；又或者有在主機系統額外安裝套件的需求。本文山姆鍋利用 Vagrant 跟 VirtualBox 虛擬技術作為快速拆建的實驗環境。</p><a id="more"></a><p>本文所使用的原始碼可以在 <a href="https://github.com/sampot/spk-cluster-lab" target="_blank" rel="noopener">GitHub</a> 上取得。</p><h2 id="設計目標">設計目標</h2><p>此實驗環境主要是針對想深入了解 K8S 如何部署與維護的運維人員，設定如下目標：</p><ol><li>近似生產環境：此實驗環境要盡可能與實際的生產環境組態相近。</li><li>支援分散式架構：多節點叢集方便模擬節點故障與新增以驗證系統的可用性、擴展性以及可靠性。</li><li>模擬雲端託管：提供負載均衡器 (load balancer) 以及持久卷 (persistent volumes) 等資源的動態建立。</li></ol><h2 id="實作考量">實作考量</h2><p>如同其他技術專案一樣，在規劃這個實驗環境時也需要面臨不同方案的取捨，以下針對幾個重要的技術選型說明背後的理由。</p><h3 id="虛擬技術">虛擬技術</h3><p>山姆鍋希望這個環境設定可以跨平台 (Windows、OS X 以及 Linux)。在實際決定選用 Vagrant + VirtualBox 之前，山姆鍋評估過使用 Multipass 作為輕量的替代方案，但由於 Multipass 缺少下列特性而打消主意：</p><ul><li>支援固定的 IP 位址：無法預先知道環境中節點的 IP 位址大大增加組態設定的複雜度。</li><li>附加額外的硬碟：由於這個環境主要是針對運維需求，也會用來實驗 K8S 不同的儲存方案，尤其是 OpenEBS 以及 ROOK。雖然某些情況下可以使用 loop device 使用檔案來模擬硬碟，但這會增加設定的複雜度也跟實際部署作法不同。</li></ul><p>另外也評估過使用 Vagrant + Libvirt (KVM) 這個方案，但對於沒有原生 Linux 環境的使用者就需要使用支援 Nested virtualization 的虛擬機方案，例如：VMWare fusion/workstation。隨著 VirtualBox 支援 Nested virtualization 的普及，之後也許會改成 Vagrant + Libvirt (KVM) 方案。</p><h3 id="K8S-發行版本">K8S 發行版本</h3><p>由於此實驗環境一般情況下是在技術人員的工作機上執行，原本也考量使用 K3S 這個輕量化的發行版本來減少記憶體等系統資源的使用量。但稍微深入思考，會發現使用 K3S 會有下列的問題：</p><ol><li>K3S 不是 Kubernetes 雲端部署環境的主流</li><li> K3S 與託管的 K8S 雲端服務架構上元件有明顯差異。</li></ol><p>由於前述理由選用 kubeadm 工具來部署跟多數雲端託管服務更相近的 K8S 叢集。</p><h3 id="組態管理工具">組態管理工具</h3><p>安裝設定方面，在使用 BASH 腳本或者 Ansible playbooks 兩者之間猶疑不定。由於已經確定選擇透過 kubeadm 來部署 K8S 叢集，使用 BASH 腳本的複雜度還在可以控制的範圍，但山姆鍋的 BASH 腳本的功力普通，如果看到憋腳的用法還請多擔待！</p><h2 id="系統需求">系統需求</h2><p>山姆鍋是在自己的 MacBook Pro (i7, 16GB RAM) 上測試整個實驗環境，最低的系統需求也跟環境節點數量以及設定有關。不過，還是建議工作機至少具備下列要求：</p><table><thead><tr><th>項目</th><th>數值</th></tr></thead><tbody><tr><td> RAM</td><td>12GB+</td></tr><tr><td>CPU</td><td>2GHz+, 4+ cores</td></tr><tr><td> 硬碟空間</td><td> 60GB+</td></tr></tbody></table><p>在工作機上要預先安裝好 Vagrant 以及 VirtualBox，相關的安裝步驟可以參考 「<a href="/post/2020/05/vagrant-virtualbox-devops-tool/" title="Vagrant+VirtualBox 跨平台虛擬環境">Vagrant+VirtualBox 跨平台虛擬環境</a>」這篇文章。</p><h2 id="叢集架構">叢集架構</h2><p>此實驗環境預設是由一個控制節點 (也就是 master node) 以及三個工作節點 (worker node) 組成。叢集底層的作業系統選擇 Ubuntu，除了是因為山姆鍋比較熟悉的系統外，在雲端託管的 K8S 服務中也是移植性 (portability) 較高的選項。</p><p>下圖是此實驗環境的架構示意圖：</p><div class="figure " style="width:;"><a class="fancybox" href="environment.drawio.svg" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="environment.drawio.svg" alt=""></a></div><h3 id="控制節點-Master-nodes">控制節點 (Master nodes)</h3><p>雖然控制節點的高可用測試也很重要，但相對於其他元件的測試頻率低很多，加上此環境主要用來作為平台元件的部署測試用途，所以預設只使用一個控制節點。這裏所謂的「平台元件」泛指為了支援應用元件而部署的服務套件，例如為了監控用途的 Prometheus, 為了日誌需要的 ELK 推疊等等。跟雲端託管環境類似，此實驗環境預設不允許將元件部署在控制節點。</p><p>此實驗環境可以支援最多三個控制節點，主機名稱 (hostname) 分別為: spkmaster-1, spkmaster-2 以及 spkmaster-3。其中，spkmaster-1 負責整個叢集的初始化工作。</p><blockquote><p>提醒：三個節點才能允許其中一個控制節點故障。即使是有兩個控制節點存在，只要其中一個故障，叢集的控制平面依然是不可用的。</p></blockquote><h3 id="控制平面端點-Control-Plane-Endpoint">控制平面端點 (Control Plane Endpoint)</h3><p>叢集中的控制節點組成一個控制平面，控制平面端點提供固定位址作為其它節點或者命令行工具 (e.g. kubectl) 存取入口。此實驗環境中，控制平面端點是由 HAProxy + Keepalived 來負責實現，即使只有單一的控制節點也是如此。有了統一的控制平面端點，控制節點可以平順地從 1 個節點擴展到 3 個。</p><h3 id="工作節點-Worker-nodes">工作節點 (Worker nodes)</h3><p>不少平台元件的高可用是基於 <a href="https://en.wikipedia.org/wiki/Quorum" target="_blank" rel="noopener">Quorum</a> 機制來避免 split-brain 問題，而為了維持 Quorum, 元件至少要有 3 個副本 (replica)。基於這個需要，此實驗環境選擇啟動 3 個工作節點以更完整模擬實際部署設定。為了支援 OpenEBS 這類透過 iSCSI 協定提供區塊裝置 (block device) 的儲存方案，工作節點也預先安裝好了 <code>open-iscsi</code> 系統套件。每個工作節點額外有一個硬碟 (/dev/sdb) 但並沒有自動附掛 (mount)，此硬碟就是為了可以測試 OpenEBS 這類的存儲方案。</p><p>此實驗環境最多可以支援九個工作節點，名稱分別為：spkworker-1 到 spkworker-9。</p><blockquote><p>之所以會有節點數量限制，是因為節點域名解析是透過 /etc/hosts 查詢，相關名稱與 IP 在建立環境時便固定了。</p></blockquote><h3 id="服務負載均衡器-Service-Loadbalancers">服務負載均衡器 (Service Loadbalancers)</h3><p>在雲端託管的 K8S 環境中，雲端供應商會提供服務負載均衡器的支援。透過這樣的支援，運維人員可以透過宣告的方式建立型態 (type) 為 LoadBalancer 的服務資源 (service resource)，雲端供應商會根據此資源物件自動建立與銷毀對應的網路負載均衡器的實例。在此實驗環境，服務負載均衡器是藉由 <a href="https://metallb.universe.tf/" target="_blank" rel="noopener">MetalLB</a> 實現。</p><h2 id="開始動手">開始動手</h2><blockquote><p>底下的指令，山姆鍋都只在 MacBook Pro 上測試過。另外，有些指令需要您根據自己的系統修改。</p></blockquote><p>首先從 GitHub 上，複製 (clone) 本文相關的程式：</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/sampot/spk-cluster-lab.git</span><br></pre></td></tr></tbody></table></figure><p>底下都假設工作目錄位於 <code>spk-cluster-lab</code> 中。</p><p>此實驗環境利用一個 <code>.env</code> 檔案來提供環境組態，使用下列指令複製範例檔：</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp .env.example .env</span><br></pre></td></tr></tbody></table></figure><p>透過 <code>.env</code> 檔案裡的變數可以調整控制節點、工作節點的數量，CPU 跟記憶體大小等等。</p><p>跟其它 Vagrant 的環境相同，可以透過指令來對環境進行操作。下面指令可以自動建置並設定好實驗環境 (第一次需要下載跟安裝，會耗費一些時間)：</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant up</span><br></pre></td></tr></tbody></table></figure><p>使用虛擬機的好處是可以使用快照 (snapshot) 來儲存與回復當前狀態。環境剛部署好時，可以使用下列指令建立一個快照:</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant snapshot save baseline</span><br></pre></td></tr></tbody></table></figure><p>其中，<code>baseline</code> 是快照名稱，您可以自己決定。</p><p>實驗測試完後，要讓環境回到已知的快照，可以使用下列指令:</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant snapshot restore baseline</span><br></pre></td></tr></tbody></table></figure><p>其它 Vagrant 虛擬機管理操作，請自行參考 <a href="https://www.vagrantup.com/docs/" target="_blank" rel="noopener">Vagrant 文件</a>。</p><p>為了避免依賴工作機的設置，程式碼儲存庫中的腳本大多假設是從第一個控制節點 (master node) 內操作，該節點同時安裝常用的工具如 kubectl, helm 等。可以透過下列指令登入第一個控制節點：</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant ssh spkmaster-1</span><br></pre></td></tr></tbody></table></figure><p>下圖是登入 spkmaster-1 後，執行 <code>kubectl get nodes</code> 的畫面：</p><div class="figure " style="width:;"><a class="fancybox" href="kubectl-get-nodes.png" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="kubectl-get-nodes.png" alt=""></a></div><h2 id="從工作機操作">從工作機操作</h2><p>雖然可以從虛擬機內進行大部分操作，但如果需要使用工作機現有的工具來操作叢集，可以按照下列步驟進行。</p><p>設定 /etc/hosts 檔案 (Windows 系統則是 c:\Windows\System32\Drivers\etc\hosts)，增加：</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">172.42.42.10  spkcluster spkcluster.lab.local</span><br></pre></td></tr></tbody></table></figure><p>‘172.42.42.10’ 是個虛擬 IP 位址作為 K8S 控制平面的端點位址，當前綁定的控制節點如果故障，此 IP 會自動轉移到另一個控制節點 (如果有設定高可用的話)。</p><p>設定 <code>KUBECONFIG</code> 環境變數，讓 <code>KUBECONFIG</code> 指到 <code>spk-cluster-lab</code> 目錄中的 <code>.kube/config</code> 檔案。在 Linux 或者 OS X 可以下列指令設定：</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> KUBECONFIG=$(PWD)/.kube/config</span><br></pre></td></tr></tbody></table></figure><p>一旦設定完成則可以使用工作機上的 <code>kubectl</code> 來進行操作。</p><h2 id="小結">小結</h2><p>此文描述的是此實驗環境的基本設定，除了高可用 K8S 叢集，GitHub 上的腳本已經可以支援服務負載均衡以及動態持久卷 (dynamic persistent volumes) 的支持。即使功能看起來完整，但山姆鍋是不建議將這樣的設置複製為生產環境的。</p><h2 id="參考資料">參考資料</h2><ul><li><a href="https://bitbucket.org/exxsyseng/k8s_ubuntu/src/master/" target="_blank" rel="noopener">k8s_ubuntu</a></li><li><a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/" target="_blank" rel="noopener">Bootstraping clusters with kubeadm</a></li><li><a href="https://medium.com/kuberverse/how-to-build-a-full-kubernetes-cluster-in-your-home-lab-using-an-automated-easy-and-fancy-way-e5853ae4e08" target="_blank" rel="noopener">How to build a full kubernetes cluster in your home lab using an automated, easy and fancy way!</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;雖然 Minikube、K3D 或者 Docker for Desktop 都提供 Kubernetes 測試環境可以方便開發雲原生應用軟體。但從運維角度來說，這些工具並不適合用來測試與驗證需要多節點的方案，例如：高可用的 etcd；K8S 的儲存方案如 &lt;a href=&quot;https://openebs.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;OpenEBS&lt;/a&gt;, &lt;a href=&quot;https://rook.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ROOK&lt;/a&gt; 等需要額外的儲存媒體 (e.g. 硬碟) 來實現；又或者有在主機系統額外安裝套件的需求。本文山姆鍋利用 Vagrant 跟 VirtualBox 虛擬技術作為快速拆建的實驗環境。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Kubernetes" scheme="https://samkuo.me/tag/kubernetes/"/>
    
      <category term="DevOps" scheme="https://samkuo.me/tag/devops/"/>
    
      <category term="SPK Cluster" scheme="https://samkuo.me/tag/spk-cluster/"/>
    
      <category term="Vagrant" scheme="https://samkuo.me/tag/vagrant/"/>
    
      <category term="VirtualBox" scheme="https://samkuo.me/tag/virtualbox/"/>
    
      <category term="HAProxy" scheme="https://samkuo.me/tag/haproxy/"/>
    
      <category term="Keepalived" scheme="https://samkuo.me/tag/keepalived/"/>
    
  </entry>
  
  <entry>
    <title>Vagrant+VirtualBox 跨平台虛擬環境</title>
    <link href="https://samkuo.me/post/2020/05/vagrant-virtualbox-devops-tool/"/>
    <id>https://samkuo.me/post/2020/05/vagrant-virtualbox-devops-tool/</id>
    <published>2020-05-20T06:52:00.890Z</published>
    <updated>2020-05-20T12:14:15.333Z</updated>
    
    <content type="html"><![CDATA[<p>山姆鍋過去雖然提過 Vagrant 以及 VirtualBox 作為開發運維的虛擬化測試環境，但卻都沒有提到過如何安裝。一方面認為這類工具安裝相當基本，一方面也認為網路上很容易就可以找到相關教學文件。由於太常用到 Vagrant，也為了能夠同時支援 Windows、OS X 以及 Ubuntu 系統的技術人員可以快速準備好環境，山姆鍋還是整理了這三個平台的安裝步驟。</p><a id="more"></a><p>本文主要是針對開發人員 (泛指會參與軟體設計、撰寫、測試以及運維的技術人員) 所撰寫，為了開發上的需要在工作機上安裝 Vagrant+VirtualBox 工具，其中工作機是指開發人員使用的筆電 (Laptop) 或者桌機 (Desktop computer)。山姆鍋是自動化的擁護者，所以安裝方式都以命令列方式進行。理想上，您可以剪貼 (copy-n-paste) 的方式按照步驟完成。</p><blockquote><p>提醒：按照本文方式安裝，各個環境的 Vagrant 跟 VirtualBox 很可能會不相同。所以，如果您的需求是各個環境都使用相同版本的軟體，本文並不適用。</p></blockquote><h2 id="前提假設">前提假設</h2><p>對於工作機的假設：</p><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td>作業系統 (OS)</td><td>Mac OS X 10.10+ / Windows 10/Ubuntu 16.04+</td></tr><tr><td> 處理器 (CPU)</td><td>i5  雙核 2.5 GHz 以上</td></tr><tr><td>主記憶體 (RAM)</td><td>8 GB 以上</td></tr><tr><td>硬碟空間 (Disk Drive)</td><td>100 GB 以上</td></tr></tbody></table><h2 id="環境設置">環境設置</h2><h3 id="準備工作">準備工作</h3><p>為了讓安裝的工作更自動，採用各個系統常用的自動套件管理工具。如果您的系統已經有安裝，可以跳過「準備動作」這一節。</p><h3 id="OS-X-Homebrew">OS X (Homebrew)</h3><p>為了後續安裝工作，需先安裝 Hombebrew 這個 OS X 套件管理工具，將下列指令貼到命令列：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/bin/ruby -e <span class="string">"<span class="variable">$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)</span>"</span></span><br></pre></td></tr></tbody></table></figure><p>另外為了安裝只提供 installer 的套件，需要使用 Cask 這個 Homebrew 擴充工具。使用下列指令安裝：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew tap caskroom/cask</span><br></pre></td></tr></tbody></table></figure><h3 id="Windows-Chocolatey">Windows (Chocolatey)</h3><p>針對 Windows 工作機，套件安裝方式採用 Chocolatey 這個工具。</p><p>在 PowerShell 執行下列指定 (PowerShell 需有管理員權限)：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Set-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString(<span class="string">'https://chocolatey.org/install.ps1'</span>))</span><br></pre></td></tr></tbody></table></figure><h3 id="Ubuntu-APT">Ubuntu (APT)</h3><p>APT 工具是 Ubuntu 系統內建，無需安裝。但為了確保套件資訊最新，須先執行下列指令：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get -y update</span><br></pre></td></tr></tbody></table></figure><h2 id="安裝-VirtualBox">安裝 VirtualBox</h2><p>在 Vagrant 支援的虛擬機技術裡，VirtualBox 具備跨平台的優點 (主要應該還是因為免費吧？)，所以通常使用 VirtualBox 與 Vagrant 搭配。</p><h3 id="OS-X-環境">OS X 環境</h3><p>使用下面指令安裝 VirtualBox:</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew cask install virtualbox</span><br></pre></td></tr></tbody></table></figure><h3 id="Windows-環境">Windows  環境</h3><p>執行下列指令自動安裝：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">choco install virtualbox</span><br></pre></td></tr></tbody></table></figure><p>手動安裝，可參考 <a href="https://school.soft-arch.net/blog/69382/install-vagrant-on-win" target="_blank" rel="noopener">https://school.soft-arch.net/blog/69382/install-vagrant-on-win</a></p><h3 id="Ubuntu-環境">Ubuntu 環境</h3><p>執行下列指令自動安裝：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install virtualbox</span><br></pre></td></tr></tbody></table></figure><h2 id="安裝-Vagrant">安裝 Vagrant</h2><p>Vagrant 讓技術人員可以描述檔方式宣告虛擬環境所要的組態，而由 Vagrant 命令列工具自動建置。</p><h3 id="OS-X-環境-v2">OS X 環境</h3><p>安裝方式，透過下列指令：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew cask install vagrant</span><br></pre></td></tr></tbody></table></figure><h3 id="Windows-環境-v2">Windows 環境</h3><p>使用下列指令安裝：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">choco install vagrant</span><br></pre></td></tr></tbody></table></figure><p>手動安裝，可參考 <a href="https://school.soft-arch.net/blog/69382/install-vagrant-on-win" target="_blank" rel="noopener">https://school.soft-arch.net/blog/69382/install-vagrant-on-win</a></p><h3 id="Ubuntu-環境-v2">Ubuntu 環境</h3><p>在命令列使用下列指令安裝 (使用者需有 sudo 權限)：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install vagrant</span><br></pre></td></tr></tbody></table></figure><h2 id="小結">小結</h2><p>隨著容器技術 (e.g. Docker) 的進展，開發團隊可以更輕量的方式確保開發測試環境的一致性，這導致了 Vagrant 慢慢在退流行。但是在運維部署這方面，虛擬機技術還是提供跟實際部署系統更相近的測試環境。由於山姆鍋最常使用 Ubuntu 系統，也很期望後起的 <a href="https://multipass.run/" target="_blank" rel="noopener">Multipass</a> 可以支援一些必要功能 (如指定 IP 位址、附加額外硬碟等等) 以適用更多情境。</p><h2 id="參考資料">參考資料</h2><ul><li><a href="https://chocolatey.org/install" target="_blank" rel="noopener">安裝 Chocolatey</a></li><li><a href="https://brew.sh/index_zh-tw" target="_blank" rel="noopener">安裝 Homebrew</a></li><li><a href="https://www.vagrantup.com/docs/" target="_blank" rel="noopener">Vagrant 官方文件</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;山姆鍋過去雖然提過 Vagrant 以及 VirtualBox 作為開發運維的虛擬化測試環境，但卻都沒有提到過如何安裝。一方面認為這類工具安裝相當基本，一方面也認為網路上很容易就可以找到相關教學文件。由於太常用到 Vagrant，也為了能夠同時支援 Windows、OS X 以及 Ubuntu 系統的技術人員可以快速準備好環境，山姆鍋還是整理了這三個平台的安裝步驟。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="DevOps" scheme="https://samkuo.me/tag/devops/"/>
    
      <category term="Ubuntu" scheme="https://samkuo.me/tag/ubuntu/"/>
    
      <category term="Windows" scheme="https://samkuo.me/tag/windows/"/>
    
      <category term="Vagrant" scheme="https://samkuo.me/tag/vagrant/"/>
    
      <category term="VirtualBox" scheme="https://samkuo.me/tag/virtualbox/"/>
    
      <category term="OS X" scheme="https://samkuo.me/tag/os-x/"/>
    
      <category term="Multipass" scheme="https://samkuo.me/tag/multipass/"/>
    
  </entry>
  
  <entry>
    <title>設定 Windows Terminal 作為 WSL 操作介面</title>
    <link href="https://samkuo.me/post/2020/05/windows-terminal-default-wsl-ubuntu-shell/"/>
    <id>https://samkuo.me/post/2020/05/windows-terminal-default-wsl-ubuntu-shell/</id>
    <published>2020-05-11T23:49:01.000Z</published>
    <updated>2020-05-11T23:49:47.878Z</updated>
    
    <content type="html"><![CDATA[<!-- excerpt --><div class="figure " style="width:;"><a class="fancybox" href="windows-terminal-ubuntu.png" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="windows-terminal-ubuntu.png" alt=""></a></div><h2 id="前言">前言</h2><hr><p>山姆鍋在使用 Surface Pro 的 Windows 系統時幾乎確定一定會開啟 Ubuntu 環境的 Shell。為了方便操作，自然希望 Windows Terminal 一開始就是進入 Ubuntu 環境。由於也會使用 Zsh + Oh My Zsh 作為操作介面，也需要安裝設定 Nerd fonts for power line。</p><h2 id="操作環境">操作環境</h2><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td>電腦</td><td> Surface Pro 4</td></tr><tr><td> 作業系統</td><td> Windows 10 Pro 繁中版 64 bit</td></tr><tr><td>Windows Terminal 版本</td><td> 0.11.1191.0</td></tr><tr><td>WSL 發行版本</td><td> Ubuntu 18.04</td></tr></tbody></table><h2 id="將-Ubuntu-18-04-設為預設開啟環境">將 Ubuntu 18.04 設為預設開啟環境</h2><p>這個設定其實很簡單，從 Windows Terminal 選單選擇<code>設定</code> (settings)，將其中的 “defaultProfile” 欄位的值改成跟 <code>Ubuntu 18.04</code>(假設這是 WSL 發行版本名稱) 相同的 GUID。也就是:</p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">'defaultProfile':</span> <span class="string">'{c6eaf9f4-32a7-5fdc-b5cf-066e8a4b1e40}'</span></span><br></pre></td></tr></tbody></table></figure><p>要跟 Ubuntu 18.04 Profile 中的 GUID 相同:</p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">'guid':</span> <span class="string">'{c6eaf9f4-32a7-5fdc-b5cf-066e8a4b1e40}'</span></span><br></pre></td></tr></tbody></table></figure><p>這樣設定後，之後開啟 Windows Terminal 就會預設開啟 <code>Ubuntu 18.04</code> 這個 Profile。</p><blockquote><p>提醒：您的設定檔中的 GUID 應該跟上述的不同。</p></blockquote><h2 id="設定開啟時的當前目錄">設定開啟時的當前目錄</h2><p>Windows Terminal 開啟 Ubuntu 18.04 環境後，預設的當前目錄是<br><code>/mnt/c/Users/&lt;使用者名稱&gt;</code>，也就是使用者在 Windows 的個人目錄在 WSL 中的掛載點。但是使用 Linux 的個人目錄習慣的應該是 <code>/home/&lt;使用者名稱&gt;</code>，要改成符合 Linux 的家 (home) 路徑，在 Windows Terminal 設定檔中，<code>Ubuntu 18.04</code> 對應的 Profile 加入 <code>commandline</code> 設定如下:</p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"commandline"</span><span class="string">:"wsl.exe</span> <span class="string">~"</span></span><br></pre></td></tr></tbody></table></figure><p>如果要使用的 WSL 發行版本不是預設，可以改為：</p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"commandline"</span><span class="string">:"wsl.exe</span> <span class="string">~</span> <span class="string">-d</span> <span class="string">'Ubuntu 20.04'</span><span class="string">"</span></span><br></pre></td></tr></tbody></table></figure><p>假設 ‘Ubuntu 20.04’ 是要預設開啟 shell 的發行版本名稱。</p><h2 id="設定配色">設定配色</h2><p>山姆鍋使用 iTerm 時習慣使用 <code>Solarized Dark</code> 做配色，在 Windows Terminal 則可以透過 <code>colorScheme</code> 來修改。Windows Terminal 剛好有支援 Solarized Dark 配色，設定如下:</p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">'colorScheme':</span> <span class="string">'Solarized Dark'</span></span><br></pre></td></tr></tbody></table></figure><h2 id="設定字型">設定字型</h2><p>在 Ubuntu 的終端操作介面，山姆鍋改使用 Zsh + On My Zsh 來提供多功能的命令提示，而為了讓提示訊息可以顯示特殊圖示需要安裝支援。到 Nerd fonts 官網的字型 <a href="https://www.nerdfonts.com/font-downloads" target="_blank" rel="noopener">下載頁面</a>，這裡山姆鍋選擇的是 <code>Hack Nerd Font</code>。</p><p>下載並安裝字型後，修改 Windows Terminal 設定，將 <code>fontFace</code> 加入 <code>defaults</code> 或者 <code>Ubuntu 18.04</code> 的 profile 中。 <code>Hack Nerd Font</code> 的設定值為:</p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">'fontFace':</span> <span class="string">'Hack NF'</span></span><br></pre></td></tr></tbody></table></figure><p>如果您選用其它字型則請更改為對應的名稱。</p><h2 id="其它設定">其它設定</h2><p>下圖總結個人主要的設定:</p><div class="figure " style="width:;"><a class="fancybox" href="terminal-settings.png" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="terminal-settings.png" alt=""></a></div><p>其它設定請自行參考 Windows Termal 的 <a href="https://github.com/microsoft/terminal/blob/master/doc/cascadia/SettingsSchema.md" target="_blank" rel="noopener">Settings schema</a>。</p><h2 id="小結">小結</h2><p>其實山姆鍋對於 Windows Terminal 的客製化需求不高，終端機操作介面的客製化較高的部分是 Zsh + Oh My Zsh，tmux 以及 vim。也因為這樣，才容易把相同的操作習慣盡可能地帶到不同的電腦。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在設定 Surface Pro 作為備用開發環境的過程中，選用 Windows Termainl 作為終端機模擬器。雖然不像 Cmder 那般強大，但作為終端機模擬器，其畫面操作效果還是令人滿意的。由於主要是以 Linux 環境為主，本文山姆鍋說明如何設定 Windows Terminal，讓它一啟動就執行 Ubuntu 文字操作介面。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Ubuntu" scheme="https://samkuo.me/tag/ubuntu/"/>
    
      <category term="WSL" scheme="https://samkuo.me/tag/wsl/"/>
    
      <category term="Windwos Terminal" scheme="https://samkuo.me/tag/windwos-terminal/"/>
    
      <category term="shell" scheme="https://samkuo.me/tag/shell/"/>
    
  </entry>
  
  <entry>
    <title>一個通用 Web 應用架構</title>
    <link href="https://samkuo.me/post/2020/05/generic-web-software-architecture/"/>
    <id>https://samkuo.me/post/2020/05/generic-web-software-architecture/</id>
    <published>2020-05-07T02:57:52.000Z</published>
    <updated>2020-05-31T09:19:47.838Z</updated>
    
    <content type="html"><![CDATA[<p>在經歷大大小小不同專案後，除了有特殊要求的系統外 (如需符合 PCI-DSS 的第三方支付服務、即時影音串流等), 大部分的 Web 應用架構其實都是大同小異。本文提供一個通用的 Web 應用架構作為參考，希望可以符合 80% 以上 Web 專案的需求。</p><a id="more"></a><p>山姆鍋是從解決實務需求為出發點，使用的一些名詞也許不符合教科書般的定義。例如：山姆鍋常常自己也搞不太清楚「系統架構」、「軟體架構」與「網路架構」該不該在同一份文件呈現？所以，可以預期山姆鍋使用的一些名詞可能會跟您認知的有所差異，為了減少混淆會先針對重要的名詞加以定義。</p><p>由於軟體架構的抽象性，多數參與開發的人員並不清楚架構的必要性。其實不管有沒有文件化，每個軟體都存在著架構。本文就是希望描述一個通用的 Web 軟體架構，協助對應用架構比較沒經驗的新創團隊有一個建構藍圖作為參考。另一方面，為了讓讀者對抽象的元件有較具體的概念，會盡可能描述該元件實作的常見選項，但不可能面面俱到，還煩請在留言處提供補充建議。</p><!-- toc --><h2 id="名詞定義">名詞定義</h2><p>山姆鍋對於軟體架構的定義很簡單：「說明系統中各個元件怎麼兜起來」。問題是：「什麼是系統？」、「什麼是元件？」，都是抽象化的名詞常常讓人搞不懂意思。</p><p>在軟體開發領域，「系統 (system)」就是子系統 (subsystem) 跟元件的組合，簡單地講：系統跟子系統只用用來將元件分組的，因為人類無法領解太過複雜的對象，傾向於將這樣整體巨觀的對象拆解成比較小的單元。以軟體開發來說，「運作中的 web 軟體」就是一個整體巨觀的對象。系統是不是一定要包含子系統？子系統要不要包含更小的子系統？這些都需要根據複雜度來考量，通常由架構師負責規劃出可以被理解的組成階層。</p><p>「元件 (component)」是另一個在不同場合被過度使用，抽象化也很高的名詞。隨著後期經驗的累積，在架構這個軟體層級，本文山姆鍋統一將元件視為可以獨立開發以及部署的單元。所以，MySQL 資料庫是個元件；微服務 (microservice) 也是元件。</p><p>「應用平台 (application platform)」提供應用所需的執行環境。以容器化應用 (containerized applications) 的話，通常會採用 Kubernetes 這樣的容器調度系統來作為應用平台基礎。</p><p>「部署環境」：根據軟體開發週期的不同階段以及使用者角色的不同，會有多個的應用平台作為部署的標的。常見的部署環境可分為「開發環境」、「測試環境 (QA environment)」、「生產環境 (production environment)」等等。</p><p>「持續部署 (continuous deployment)」指將經過品質確保的應用元件持續且自動地部署到生產環境，每次元件部署就會產生一個新的版本與原先版本並存一段時間。透過 feature flag 等機制，完成部署不代表已經釋出 (released) 給終端使用者。讓生產環境的部署與釋出分開的作法，允許團隊使用 canary 或 blue green 等不同發行 (release) 策略來降低造成對終端用戶大規模衝擊的風險。</p><h2 id="前提假設">前提假設</h2><p>本文所提的架構設計基於下列假設：</p><ol><li>Web 應用按照 <a href="https://12factor.net/" target="_blank" rel="noopener">The Twelve Factors App</a> 原則設計。</li><li>採用 Client-server 網路架構。</li><li>採用 Kubernetes 作為應用平台，工程師有自己本機的開發環境。</li><li>團隊可以根據元件特性，自由選擇實作的程式語言、框架跟資料存儲。</li></ol><h2 id="設計目標">設計目標</h2><ul><li>自建應用平台只使用開源軟體。</li><li>具備移植性 (portability) 可以自建應用平台或者選擇雲端託管服務 (EKS、GKE、AKS)。</li><li>具備可用性 (availability) 與擴充性 (scalability)。</li></ul><h2 id="架構設計">架構設計</h2><p>雖然架構設計盡量抽象化，但一個務實的架構師其實在設計階段，心中或多或少已經有元件實作的選項。這點通常也沒什麼問題，甚至可以說是優點之一。畢竟，您不會希望架構設計只是設計，無法轉換成對應的實作吧！所以，山姆鍋其實都是從已經知道元件具體如何實現才加以抽象化描述，因為山姆鍋知道團隊一定會有人 (例如: IT 工程師) 提出某某元件應該採用哪個產品等等問題。</p><p>下圖是本文所提的 Web 應用架構圖：</p><hr><div class="figure " style="width:;"><a class="fancybox" href="generic-web-architecture.png" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="generic-web-architecture.png" alt=""></a></div><h3 id="應用客戶端-Application-clients">應用客戶端 (Application clients)</h3><p>由於本文描述 Web 應用架構，應用客戶端自然是透過 Web 瀏覽器來執行。應用客戶端按照實作方式不同可以分成下列幾種：</p><ol><li><p>多頁式 Web 應用：藉由在後端動態產生網頁的 HTML 來實現使用者介面，使用者每次的點選動作都會發出新的請求來產生新頁面。</p></li><li><p>單頁式 Ｗeb 應用 (Single Page Application; SPA)：透過 Ajax 機制在不換頁的情況下，動態部分修改網頁內容來呈現使用者介面。相較於傳統多頁式應用提高使用者介面的反應速度。</p></li><li><p>漸進式 Web 應用 (Progressive Web Application; PWA)：比單頁式 Web 應用更進一步，利用新技術 (如 service worker, web push 等) 讓 Web 應用更接近原生 (行動) 應用的使用體驗。</p></li></ol><p>對於新專案建議以 PWA 作為客戶端的實現方式，PWA 應用框架常見方案：</p><ul><li><a href="https://vuejs.org/" target="_blank" rel="noopener">Vue.js</a></li><li><a href="https://zh-hant.reactjs.org/" target="_blank" rel="noopener">React</a></li><li><a href="https://angular.io/" target="_blank" rel="noopener">Angular</a></li></ul><div class="alert info no-icon"><p><em>部署觀點</em><br>Web 應用的客戶端元件雖然在瀏覽器中執行，但所需的程式碼及資源檔 (e.g. CSS/images) 是以「應用服務」元件形式部署在平台，當瀏覽器存取才下載到客戶端呈現或執行。根據客戶端的特性，呈現頁面可能同時會有客戶端以及服務端邏輯。例如：多頁式應用，每頁都是由後端服務動態產生；新型態的 PWA 也可能為了搜尋引擎優化 (SEO) 目的而進行服務端渲染 (Server-Side Rendering; SSR)。</p></div><div class="alert info no-icon"><p><em>安全觀點</em><br>應用客戶端的程式碼與資源檔只能透過安全連線 (HTTPS) 被下載。同樣地，在瀏覽器執行的程式碼只透過安全連線 (HTTPS/WSS) 與服務端通訊。</p></div><h3 id="域名服務-Domain-Name-Service-DNS">域名服務 (Domain Name Service; DNS)</h3><p>域名服務是使用者存取應用的第一個網路環節，應用客戶端要存取後端應用服務需要將域名解析 (resolve) 成 IP 位址才能實際透過網路存取。「域名服務」通常需要跟「內容交付網路」搭配，在客戶端解析域名時，根據客戶端所在的地點以及網路狀態來回傳適當的伺服器節點。</p><p>不在此架構涵括範圍，但如果應用部署在多個資料中心，DNS 也是實現全球負載均衡的必要機制。</p><p><em>雲端常見的方案：</em></p><ul><li>CloudFlare</li><li>AWS Route 53</li></ul><p>由於 DNS 對於應用服務的可用性扮演至關重要的地位，新創團隊沒有資源實現全球高可用的域名服務，應該選擇採用雲端服務。這裡的域名服務是提供給客戶端使用，跟應用平台內部的域名服務是分開的。</p><h3 id="內容交付網路-Content-Delivery-Network-CDN">內容交付網路 (Content Delivery Network; CDN)</h3><p>「內容交付網路」，也就是 CDN，負責將客戶端需要的資源檔案或程式碼快取到世界各地的邊緣 (edge) 資料中心來減少客戶端存取的延遲以及提高應用的處理容量跟可靠性。此外，CDN 服務供應商通常也提供 Web 應用防火牆 (web application firewall; WAF) 服務來強化 web 應用的安全性。應用如果是面向全球的使用者，則 CDN 的使用應該視為必要。</p><p><em>雲端常見的方案：</em></p><ul><li>CloudFlare CDN</li><li>AWS CloudFront</li><li>Ｇoogle Cloud CDN</li></ul><p>在過往應用系統要能夠使用 CDN 是門檻相當高的事情，主要是費用問題。由於經濟型以及免費的 CDN 服務已經很常見，且 CDN 是實現應用高擴充性中重要的元件，因此被納入此架構中。</p><h3 id="網路負載均衡器-Network-Load-balancer">網路負載均衡器 (Network Load balancer)</h3><p>支援第四層 (TCP/UDP) 的網路負載均衡，根據連線的 IP 與 Port 將請求平均轉送 (forward) 給應用平台內的各個「邊緣代理 (edge proxy)」。</p><p><em>開源常見的方案：</em></p><ul><li><a href="https://github.com/haproxy/haproxy" target="_blank" rel="noopener">HAProxy</a>: 配合 <a href="http://www.linux-ha.org/wiki/Heartbeat" target="_blank" rel="noopener">Hearbeat</a> 或者 <a href="https://www.keepalived.org/" target="_blank" rel="noopener">Keepalived</a> 藉由 <a href="https://en.wikipedia.org/wiki/Virtual_IP_address" target="_blank" rel="noopener">Virtual IP</a> 機制可提供容錯。</li><li><a href="https://github.com/metallb/metallb" target="_blank" rel="noopener">MetalLB</a>: 與 K8S 有良好整合，但目前還是 beta 狀態。</li></ul><p>常見的雲端託管服務都有整合各家的網路負載服務器，只要在 K8S 中部署型態 (type) 為 <code>LoadBalancer</code> 的服務 (service) 資源就可以建立對應的負載均衡服務。</p><h3 id="邊緣代理-Edge-Proxy">邊緣代理 (Edge Proxy)</h3><p>負責應用平台請求的進入點，通常俱備下列功能：</p><ol><li>提供與客戶端的加密安全連線 (SSL termination)。</li><li>將請求轉送到正確的上游 (upstream) 的應用控制器或服務元件。</li><li>請求限速 (Rate limit): 避免單一來源 (e.g. 同一 IP 或用戶) 同一時間發出太多請求，部分是為了防堵「阻斷服務 (DoS)」。</li><li>存取控制 (Access control)：驗證請求中的 token 來決定是否允許存取。</li><li>標示請求識別碼：針對每個進入平台的請求給予唯一識別碼，讓追蹤系統可以關聯同一個請求在不同元件的資訊。</li></ol><p><em>開源常見的方案：</em></p><ul><li><a href="https://github.com/kubernetes/ingress-nginx" target="_blank" rel="noopener">Nginx</a></li><li><a href="https://github.com/Kong/kubernetes-ingress-controller" target="_blank" rel="noopener">Kong</a></li></ul><p>此元件利用 Kubernetes 的 Ingress controller 實現。</p><h3 id="應用控制器-Application-Controller">應用控制器 (Application Controller)</h3><p>此架構中的選擇性 (optional) 元件，負責：</p><ol><li>將 HTTP 請求轉發給應用的不同元件。</li><li>根據負載來伸縮 (scale) 應用元件副本 (replica) 數量：實際上通常由另一個元件負責，但此架構將兩者合併。</li></ol><p><em>開源常見的方案：</em></p><ul><li><a href="https://github.com/knative/serving" target="_blank" rel="noopener">Knative Serving</a></li><li><a href="https://github.com/openfaas/faas" target="_blank" rel="noopener">OpenFaaS</a></li></ul><p>雖然習慣將這樣的方案稱為 Function as a Service (FaaS) 框架，此架構利用這些框架擴展 Kubernetes 對於應用元件的生命週期管理功能。如果需要更彈性的自動擴容 (autoscaling)，包括從零擴容 (scale from zero) 的能力，則可以在平台中使用「應用控制器」。</p><h3 id="應用服務-Application-Service">應用服務 (Application Service)</h3><p>一個 Web 應用由一個以上的「應用服務」組成，單體結構 (monolithic) 的應用只有一個應用服務，但並不是說有多個應用服務就是屬於微服務架構 (microservices)。在此架構並沒有對應用服務的數量以及結構加以限制，應用服務可以是一個「功能 (function)」、微服務、或者是包含整個應用邏輯的單體。應用服務包含不適合在客戶端實現的商務邏輯 (business logic) 以及領域模型 (domain model)，通常由開發團隊內部開發，但就算是外包只要是應用特有 (application-specific) 的元件都屬於這一類，也應該採取相同架構規範。</p><p><em>實作應用服務常用的程式語言：</em></p><ul><li>Python</li><li>Go</li><li>Java</li><li>JavaScript/TypeScript</li><li>Ruby</li><li>PHP</li><li>C#</li></ul><p>除了實現應用邏輯所需的程式碼，應用服務也需要明確指定相依的套件名稱與版本，在 CI/CD 的 pipeline 就完成應用製品 (artifact) 的封裝工作，如產生容器的映像檔並推送到容器儲存庫 (container registry) 中。除了開發環境外，其餘的部署都只能使用封裝好的容器映像檔來進行。</p><p>另外，只要是熱門的程式語言，選擇哪一種則按照團隊成員已經熟悉為準，初期不用為了執行效能或為符合流行趨勢來選擇。</p><div class="alert info no-icon"><p><em>部署觀點</em><br>每個應用服務都是以容器映像 (container image) 形式包裝 (package) 跟分發 (delivery)，容器已包含應用服務執行時期 (runtime) 以及相依的程式庫、執行檔等。一般原則是不建議在部署環境才建置 (build) 應用服務，一些 FaaS 方案（如 Fission) 支援在部署環境中才建置功能 (funtion) 容器用以執行對應的功能。雖然可以免除容器儲存庫 (container registry) 的需求，但並無法保證每次建置時相依的套件可以正常取得。如果應用有多個部署環境，也會增加組態飄移 (configuration drift) 的可能。</p></div><div class="alert info no-icon"><p><em>安全觀點</em><br>為了避免應用元件所在的主機 / 容器被入侵後將機密資料送出，應用服務不應該直接存取網路上的第三方服務。也就是說：應用服務元件所需要的服務都只能由「支援服務」或者「支援存儲」來提供。如此可以透過防火牆或者網路策略 (Network policy) 等機制來限制只有合法授權元件可以存取。</p></div><h3 id="支援服務-Backing-Services">支援服務 (Backing Services)</h3><p>泛指由第三方所提供套裝軟體或者雲端供應商提供的網路服務。通常「支援服務」的整備 (provision) 流程是運維團隊建立所需的「支援服務」實例後，將該服務實例與應用服務進行綁定 (binding)。理想上，應用元件不需要了解背後的整備流程。</p><p>以 MySQL 資料庫為例：「整備」包含部署 MySQL 服務軟體 (或者申請雲端資料庫服務)、建立資料庫，產生應用連線的帳密跟設定存取權限等；「綁定」則是將存取 MySQL 資料庫所需的服務位址、連線帳密等資訊以 <a href="https://kubernetes.io/docs/concepts/configuration/configmap/#configmap-object" target="_blank" rel="noopener">ConfigMap</a> 或者 <a href="https://kubernetes.io/docs/concepts/configuration/secret/" target="_blank" rel="noopener">Secret</a> 資源形式讓應用服務可以取得。</p><p>簡單的整備流程可以手動安裝，也可以透過 <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/service-catalog/" target="_blank" rel="noopener">Service Catalog</a> 來自動進行。</p><h3 id="支援存儲-Backing-Stores">支援存儲 (Backing Stores)</h3><p>架構上同樣屬於支援服務，但由於負責提供應用狀態存放與查詢所需的機制，跟其它無狀態的支援服務在部署與安全策略明顯不同，架構上特別分開描述。「支援存儲」按照應用對資料的永續性 (persistence)、資料結構、查詢效能等不同需求會有不同適用的存儲方案。</p><ul><li>「資料存儲服務」提供應用永久性或半永久性資料的存放空間，同時需要提供應用透過網路協定來快速查詢與處理資料的功能。</li><li>「資料快取服務」提供應用暫時性的資料存放空間，提供快速查詢常用資料機制以達到縮減請求處理時間的目的。</li><li>「搜尋索引服務」提供全文檢索功能，對於想提供使用者 ad-hoc 資料查詢功能的應用特別需要。</li><li>「共享檔案系統」提供可由多節點同時存取的網路檔案存取服務，傳統上透過 NFS 來提供。Web 應用常用來存放使用者上傳的媒體檔案。</li><li>「物件存儲服務」由 AWS S3 服務引起流行的存儲模式，適合非結構化、大量的二進位物件 (blob) 檔案存取。由於物件儲存高可用性以及擴展性，在現代化的 Web 應用，常用來取代「共享檔案系統」的角色。</li></ul><p>此架構設計允許應用元件選擇最適合的存儲方案，但是否真得需要根據資料特性來選擇？這要由團隊自行決定。極端而言，有些應用將所有資料包括檔案都存放在一個關聯式資料庫來集中管理，對效能、可用性以及擴充性當然有不好的作用，但是粗暴簡單。</p><h2 id="常見支援存儲">常見支援存儲</h2><p>應用服務為無狀態元件，所以 Web 應用總是需要某些「支援存儲」來存放狀態資料，本節提出幾種常見的支援存儲。</p><h3 id="資料存儲-Data-Stores">資料存儲 (Data Stores)</h3><p>資料存儲或者說資料庫 (database) 按照資料模型的不同可分為「關聯式資料庫 (RDBM)」與非關聯式資料庫 (NoSQL) 兩大類。</p><p>Wikipedia 對於關聯式資料庫的定義：</p><blockquote><p>關聯式資料庫（英語：Relational database），是建立在關聯模型基礎上的資料庫，藉助於集合代數等數學概念和方法來處理資料庫中的資料。現實世界中的各種實體以及實體之間的各種聯絡均用關聯模型來表示。關聯模型是由埃德加・科德於 1970 年首先提出的，並配合「科德十二定律」。現如今雖然對此模型有一些批評意見，但它還是資料儲存的傳統標準。標準資料查詢語言 SQL 就是一種基於關聯式資料庫的語言，這種語言執行對關聯式資料庫中資料的檢索和操作。</p></blockquote><p>Wikipedia 對於 NoSQL 的簡短說明：</p><blockquote><p>NOSQL (Not Only SQL) 是對不同於傳統的關聯式資料庫的資料庫管理系統的統稱。</p><p>允許部分資料使用 SQL 系統儲存，而其他資料允許使用 NOSQL 系統儲存。其資料儲存可以不需要固定的表格模式以及中介資料 (metadata)，也經常會避免使用 SQL 的 JOIN 操作，一般有水平可延伸性的特徵。</p></blockquote><p>選擇哪類型來作為應用的資料庫可以根據需求與運維能力而定。作為一般原則：由於關聯式資料庫技術最為成熟以及使用廣泛，新創團隊應該優先採用。</p><p><em>開源常見的方案：</em></p><ul><li><a href="https://github.com/mysql/mysql-server" target="_blank" rel="noopener">MySQL</a></li><li><a href="https://www.postgresql.org/" target="_blank" rel="noopener">PostgreSQL</a></li><li><a href="https://github.com/mongodb/mongo" target="_blank" rel="noopener">MongoDB</a></li><li><a href="https://github.com/antirez/redis" target="_blank" rel="noopener">Redis</a></li></ul><p>Redis 適用不需要 Ad-hoc 查詢，可以接受短時間 (如 1 秒）資料丟失風險的應用情境。</p><h3 id="資料快取-Data-Cache">資料快取 (Data Cache)</h3><p>資料快取服務提供應用元件暫時性 (transient) 資料的存放服務，用來減少需要存取資料庫的次數以達到提高服務請求的效率。例如使用者的會期資料 (session data) 在每個網頁請求都需要存取，就可以放在資料快取中減少查詢時間。</p><p>開源常見方案：</p><ul><li><a href="https://github.com/antirez/redis" target="_blank" rel="noopener">Redis</a></li><li><a href="https://github.com/memcached/memcached" target="_blank" rel="noopener">Memcached</a></li></ul><p>由於 Redis 具備多樣性功能，山姆鍋傾向於使用 Redis, 在某些情境甚至可以作為 key-value 資料庫使用。</p><h3 id="搜尋索引-Search-Index">搜尋索引 (Search Index)</h3><p>如果應用需要提供全文檢索 (full-text search) 功能，由於資料庫對於全文檢索的支援相對陽春，應用也許需要使用專門的搜尋引擎 (search engine) 軟體來符合查詢效能的需求。</p><p><em>開源常見的方案：</em></p><ul><li><a href="https://github.com/elastic/elasticsearch" target="_blank" rel="noopener">Elasticsearch</a></li><li><a href="https://github.com/apache/lucene-solr/" target="_blank" rel="noopener">Solr</a>。</li></ul><h3 id="共享檔案系統-Shared-Filesystem">共享檔案系統 (Shared Filesystem)</h3><p>在分散式應用架構中，常見的一個需求是：使用者上傳的檔案 (通常是圖檔) 要讓應用的多個節點可以存取，傳統上可以透過網路檔案系統 (如 NFS) 來提供。使用共享檔案系統的主要好處在於熟悉以及方便開發，讀寫本地跟遠端掛載的檔案操作差異不大。</p><p><em>開源常見的方案</em></p><ul><li><a href="https://github.com/gluster/glusterfs" target="_blank" rel="noopener">GlusterFS</a></li><li><a href="https://docs.ceph.com/docs/master/cephfs/" target="_blank" rel="noopener">Ceph FS</a></li></ul><p>由於雲端供應商較少提供共享檔案系統服務，如果使用共享檔案系統就需要自行部署。因此，如果可行建議採用「物件存儲」代替。</p><h3 id="物件存儲-Object-Storage">物件存儲 (Object Storage)</h3><p>相對於共享檔案系統雖然需要透過 API 來進行檔案操作，由於難度不高並不會增加太多額外負擔 (overhead)。使用雲端物件存儲服務還具備高可用以及高可靠的優勢，檔案存放在雲端物件存儲通常也方便與 CDN 整合 (e.g. AWS CloudFront + S3)。在本地開發上，MinIO 提供相容的功能可以方便整合測試。</p><p><em>開源常見的方案：</em></p><ul><li><a href="https://min.io/" target="_blank" rel="noopener">MinIO</a></li><li><a href="https://ceph.io/ceph-storage/object-storage/" target="_blank" rel="noopener">Ceph RGW</a></li></ul><p>由於雲端物件存儲服務按量計費，且有經濟的選項，如 DigitalOcean 的 <a href="https://www.digitalocean.com/products/spaces/" target="_blank" rel="noopener">Spaces</a>。原則上，即使是自建應用平台也建議採用雲端物件存儲服務。</p><h2 id="常見支援服務">常見支援服務</h2><p>不同 Web 應用需要的支援服務差異頗大，但還是有幾種「支援服務」常需要用到。</p><h3 id="訊息傳遞服務-Messaging-service">訊息傳遞服務 (Messaging service)</h3><p>「訊息傳遞服務」提供應用元件間一對ㄧ (queue)、一對多 (publish-subscribe) 等多種通訊模式的訊息傳遞機制。此服務的應用場景之一是應用將實現請求不需要立即完成的工作透過佇列 (queue) 派送給背景程序執行，如此可以減少客戶端等待時間。幾乎沒有一個高擴充性 (highly scalable) 的系統找不到訊息傳遞服務的存在。所以，熟悉跟了解訊息互動模式，更重要的是事件驅動 (event-driven) 概念，對於設計高可用以及高擴充性的應用相當關鍵。</p><p><em>開源常見的方案：</em></p><ul><li><a href="https://github.com/apache/kafka" target="_blank" rel="noopener">Kafka</a></li><li><a href="https://github.com/rabbitmq/rabbitmq-server" target="_blank" rel="noopener">RabbitMQ</a></li><li><a href="https://github.com/nats-io/nats-streaming-server" target="_blank" rel="noopener">NATS</a></li><li><a href="https://github.com/antirez/redis" target="_blank" rel="noopener">Redis</a></li></ul><p>Redis 真的是多用途的軟體，在小規模的應用也常看到作為訊息傳遞服務。山姆鍋不負責任建議：如果沒有特別需要的話，可以選擇 NATS Streaming Server。</p><h3 id="郵件寄送服務-Email-Delivery-Service">郵件寄送服務 (Email Delivery Service)</h3><p>此服務提供應用發送電子郵件所需的功能，讓 Web 應用發送諸如：「使用者信箱確認信件」、「密碼重置信件」等電子郵件。由於垃圾信氾濫，自建郵件服務信件送達機率越來越低，建議採用雲端服務。</p><p><em>雲端常見的方案：</em></p><ul><li><a href="https://sendgrid.com/" target="_blank" rel="noopener">SendGrid</a></li><li><a href="https://www.sendinblue.com/" target="_blank" rel="noopener">SendinBlue</a></li></ul><p>應用需透過 SMTPS 協定與郵件寄送服務溝通避免供應商鎖定 (vendor lock-in) 以及方便測試。開發環境會需要利用 <a href="https://github.com/derekahn/mailslurper" target="_blank" rel="noopener">MailSluper</a> 這類工具來進行模擬跟除錯。</p><div class="alert info no-icon"><p><em>安全觀點</em><br>對應 “應用服務元件不能直接存取第三方服務 “這個限制，須在應用平台 (生產環境) 部署對應的代理 (proxy) 服務，與雲端服務連線只能由此代理進行。對應用元件而言，郵件寄送服務是由此代理所提供，因為代理也是平台所管理的元件，存取控制可以一致地使用應用平台的機制實現 (如 Network policy, Service Mesh)。</p></div><h2 id="其它支援服務">其它支援服務</h2><p>實務上應用平台至少還要部署應用監控、日誌等其它所需的服務，但由於不是應用元件執行所直接相依的服務，這裡就不特別說明。除此之外，就運維一個應用平台而言，服務網格 (service mesh)、分散式追蹤 (distributed tracing) 等用來提高應用系統可觀察性 (observability) 以及可靠性 (reliability) 的技術，都是團隊值得考慮投資的項目。</p><h2 id="元件間通訊機制">元件間通訊機制</h2><p>應用元件並非獨立存在，彼此間免不了需要進行溝通，例如客戶端需要呼叫後端 API 來查詢資料；微服務需要呼叫另一個微服務來完成客戶端過來的請求。元件之間要能夠順利溝通，自然就需要有規範的通訊協定，本節針對幾個情境提出常見選項。</p><h3 id="客戶端-服務端">客戶端 - 服務端</h3><p>雖然可以做到一定離線 (offline) 操作能力，但 Web 應用的客戶端總是免不了需要跟後端服務溝通的。下面幾個通訊協定以及適用的情境：</p><ul><li>REST (HTTPS): 適合由客戶端發起進行查詢或者操作的 API 請求。</li><li>Websocket (WSS): 適合客戶端與服務端需要即時雙向的通訊，如即時股價回報。</li><li>gRPC (HTTP/2): 適合客戶端是行動應用或者其它 <a href="https://en.wikipedia.org/wiki/Fat_client" target="_blank" rel="noopener">Thick clients</a>。</li></ul><h3 id="服務端-服務端">服務端 - 服務端</h3><p>應用服務元件之間的通訊機制如果是同步的請求回應 (request-response) 互動模式，雖然看起來 gRPC 是不二選擇，但 REST API 或者 JSON-RPC 其實也是簡單務實的作法。</p><p>除非對網路流量優化或者訊息 schema 驗證有特別的需求，不然應用服務元件間非同步通訊則建議以 JSON 為訊息的格式，夠彈性也方便找問題。</p><h2 id="小結">小結</h2><p>山姆鍋希望本文所提的 Web 應用架構剛好足夠 (just enough) 適用多數 Web 專案的需要。新創團隊想要一開始就使用先進 (state-of-the-art) 的技術框架作為賣點之一，雖然可以理解但同時也會增加不必要的風險。畢竟軟體的價值發生在實際交付使用者的時候，初期投資太多在酷炫技術對使用者並沒有實際效益。針對新創團隊，即使目標是微服務架構，山姆鍋仍建議從單體式應用服務作為開始，在實際掌握領域 (domain) 如何適當劃分的經驗後，再過渡到微服務架構應該是比較保險的作法。採用微服務架構的話，可以評估是否以及哪個時間點導入「服務網格 (service mesh)」機制。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在經歷大大小小不同專案後，除了有特殊要求的系統外 (如需符合 PCI-DSS 的第三方支付服務、即時影音串流等), 大部分的 Web 應用架構其實都是大同小異。本文提供一個通用的 Web 應用架構作為參考，希望可以符合 80% 以上 Web 專案的需求。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Kubernetes" scheme="https://samkuo.me/tag/kubernetes/"/>
    
      <category term="Software architecture" scheme="https://samkuo.me/tag/software-architecture/"/>
    
      <category term="Web Application platform" scheme="https://samkuo.me/tag/web-application-platform/"/>
    
  </entry>
  
  <entry>
    <title>讓程式從 WSL 環境自動開啟 Windows 系統的瀏覽器</title>
    <link href="https://samkuo.me/post/2020/05/launch-windows-default-browser-from-inside-wsl/"/>
    <id>https://samkuo.me/post/2020/05/launch-windows-default-browser-from-inside-wsl/</id>
    <published>2020-05-04T02:11:41.000Z</published>
    <updated>2020-05-04T02:11:41.945Z</updated>
    
    <content type="html"><![CDATA[<p>在使用 Hexo 撰寫部落格文章或者開發 Web 應用時常常會需要開啟瀏覽器來檢視結果。Hexo 或者 Web 應用開發工具除了支援啟動後端服務外也支援自動啟動系統預設的瀏覽器，但由於在 WSL 環境預設並沒有圖形桌面環境，自然無法開啟瀏覽器。本文山姆鍋將說明如何讓 WSL 中的程式可以自動開啟 Windows 系統預設的瀏覽器。</p><a id="more"></a><p>要讓程式自動開啟瀏覽器通常會有特別的參數設定。例如：Hexo 可執行下列指令啟動本地網頁服務並開啟預設的瀏覽器來連到網址 “<a href="http://127.0.0.1:4000" target="_blank" rel="noopener">http://127.0.0.1:4000</a>”。</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo server --open</span><br></pre></td></tr></tbody></table></figure><p>但由於上述原因並不能如預期運作。所以，往往需要手動開啟 Windows 上的瀏覽器並輸入網址來開啟網頁，雖然不算大問題，但是也太不方便。</p><h2 id="探索">探索</h2><p>稍微研究一下 Linux 上程式如何開啟預設瀏覽器的問題，可以了解像是上述 <code>hexo server --open</code> 指令內部其實通常是透過 ‘xdg-open’ 這個程式來開啟桌面環境預設的應用程式。例如： <code>xdg-open https://google.com</code> 試圖開啟瀏覽器連結到 ‘<a href="https://google.com" target="_blank" rel="noopener">https://google.com</a>’ 這個網址。‘xdg-open’ 則會根據環境盡可能達成開啟應用的目的。</p><h2 id="實現">實現</h2><p>在 WSL Ubuntu 環境中，‘xdg-open’ 包含在’xdg-utils’ 這個套件中。執行下列指令安裝 ‘xdg-utils’ 套件：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt install xdg-utils</span><br></pre></td></tr></tbody></table></figure><p>在命令列執行下列指令測試是否正常：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ xdg-open https://samkuo.me</span><br></pre></td></tr></tbody></table></figure><p>可以開啟 Windows 預設瀏覽器 (如 Chrome)，並連到山姆鍋的個人部落格的話則表示運作成功 :-)</p><p>以上是在 Ubuntu 20.04 WSL 發行版本上測試，很顯然也應該只對使用 ‘xdg-open’ 的程式有效。另外，如果 WSL 系統已經安裝了 Linux 原生桌面環境 (如 xfce4), 由於’xdg-open’會優先試圖使用 Linux 桌面環境的設定來開啟瀏覽器，會導致經過好幾分鐘後才會開啟 Windows 預設的瀏覽器。</p><h2 id="小結">小結</h2><p>山姆鍋原先並沒有預期這樣的作法可以在 WSL 環境中正常運作，純粹只是抱著實驗看看的想法。至於可以運作的原因，由於 WSL 本身就支援從 Ｌinux 環境直接啟動 Windows 原生程式，個人猜測 Ubuntu WSL 發行版本可能對於 ‘xdg-open’ 剛好有特別支援。不管如何，WSL 作為開發環境的可行性又更高了一點。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在使用 Hexo 撰寫部落格文章或者開發 Web 應用時常常會需要開啟瀏覽器來檢視結果。Hexo 或者 Web 應用開發工具除了支援啟動後端服務外也支援自動啟動系統預設的瀏覽器，但由於在 WSL 環境預設並沒有圖形桌面環境，自然無法開啟瀏覽器。本文山姆鍋將說明如何讓 WSL 中的程式可以自動開啟 Windows 系統預設的瀏覽器。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="xdg-open" scheme="https://samkuo.me/tag/xdg-open/"/>
    
      <category term="WSL" scheme="https://samkuo.me/tag/wsl/"/>
    
  </entry>
  
  <entry>
    <title>WSL 開發環境改為在 Ubuntu 中執行 Docker</title>
    <link href="https://samkuo.me/post/2020/05/wsl-switch-to-docker-ce-in-linux/"/>
    <id>https://samkuo.me/post/2020/05/wsl-switch-to-docker-ce-in-linux/</id>
    <published>2020-05-03T02:15:58.000Z</published>
    <updated>2020-05-04T08:27:29.543Z</updated>
    
    <content type="html"><![CDATA[<p>雖然 Docker Desktop for WSL 利用 WSL 來執行 Linux 容器，一方面提高容器在 Windows 環境的執行效率，一方面也提高記憶體等資源與主機系統的共用程度。雖然相對之前採用完整虛擬機相對節省資源，但對山姆鍋的低配 Surface Pro 來說還是太佔資源。也由於 WSL 2 已經可以直接執行 Docker engine 來支援 Linux 容器的執行，所以決定改採用這個方式來提供 Docker 服務。</p><a id="more"></a><p>在「<a href="/post/2020/04/dev-env-docker-wsl2-k3d-vs-code/" title="Docker Desktop for WSL2 容器化開發環境">Docker Desktop for WSL2 容器化開發環境</a>」這篇文章說明山姆鍋為何嘗試改造 Surface Pro 成為替代的開發環境，本文是基於該環境設定所做的修改。</p><h2 id="改在-WSL-內執行-Docker-Engine-的優缺點">改在 WSL 內執行 Docker Engine 的優缺點</h2><p>雖說主要優點是節省執行時期的系統資源，但因為 WSL Ubuntu 尚並不支援 Systemd，這會導致像 Docker CE 這樣以 daemon 形式執行的服務無法隨 Ubuntu 系統啟動時自動執行。這也不難理解，畢竟 WSL 只是用來作為開發用途，不是真正用來執行對外服務。由於這個 Surface Pro 只有在用作工作時才需要執行 Ubuntu 環境 (主要用途還是移動時在 Windows 環境使用)，這點對山姆鍋來說不算是問題。</p><h2 id="失敗的嘗試">失敗的嘗試</h2><p>從 Google 搜尋相關的教學文章會發現有些會說只需要透過 <code>sudo apt install docker.io</code> 安裝就可以。但山姆鍋試過後發現這樣的安裝方式並無法使用 <code>sudo service docker start</code> 指令來正常啟動 Docker engine，會出現無法找到 “docker” 服務的錯誤。也許是山姆鍋的操作步驟有錯誤，但改用 Docker 官方<a href="https://docs.docker.com/engine/install/ubuntu/" target="_blank" rel="noopener">安裝文件</a>卻可以正常運作。所以，最後是採用 Docker 官方的安裝步驟。</p><h2 id="安裝-Docker-CE">安裝 Docker CE</h2><p>安裝方式就是按照 Docker 官方提供的文件說明，按照步驟在 Ubuntu 18.04 系統中進行。如前面所述，這樣的安裝方式並無法自動執行 Docker 服務，需要自行手動執行下列指令來啟動：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo service docker start</span><br></pre></td></tr></tbody></table></figure><p>一旦 Docker 服務啟動後，操作就跟在其它環境相同。</p><div class="figure " style="width:;"><a class="fancybox" href="start-docker-service.png" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="start-docker-service.png" alt=""></a></div><h2 id="讓-Windows-環境可以連到-WSL-中的-Docker">讓 Windows 環境可以連到 WSL 中的 Docker</h2><p>山姆鍋自己目前並沒有這個需求，但如果您需要讓 WSL 中的 Docker 服務可以被 Windows 的程式存取 (甚至其它電腦，但不建議)，需要額外做一些設定。</p><h3 id="開放-Docker-服務的-TCP-埠">開放 Docker 服務的 TCP 埠</h3><p>預設 Docker engine 只監聽 Unix socket 來讓客戶端連線操作，為了讓 Windows 環境中的程式可以存取，需要開放可以使用 TCP 透過網路存取。</p><p>使用 vim 或者其它文字編輯器修改檔案 “/etc/default/docker” 中的 <code>DOCKER_OPTS</code> 如下所示：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DOCKER_OPTS=<span class="string">"-H tcp:127.0.0.1:2375 -H unix:///var/run/docker.sock"</span></span><br></pre></td></tr></tbody></table></figure><p>您也可根據需要增加其它給 Docker engine 的參數。 如果 Docker 已經在執行，需要重啟讓新參數生效。</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo servie docker restart</span><br></pre></td></tr></tbody></table></figure><h3 id="設定-Windows-環境變數">設定 Windows 環境變數</h3><p>Docker 的客戶端大多可以透過 <code>DOCKER_HOST</code> 這個環境變數來改變要連線的 Docker 服務。所以，需要在 Windows 環境中新增該環境變數，內容為 <code>tcp://127.0.0.1:2375</code>。</p><p>在 Windows 10 可以透過「開始」選單，輸入 “系統” 找到控制台中的「系統」選項</p><div class="figure " style="width:;"><a class="fancybox" href="start-control-panel.png" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="start-control-panel.png" alt=""></a></div><p>打開後選 「進階系統設定」–&gt; 「環境變數 (N)…」後，在對話筐中新增。</p><div class="figure " style="width:;"><a class="fancybox" href="add-docker-host-env-var.png" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="add-docker-host-env-var.png" alt=""></a></div><h2 id="登入時啟動-WSL-以及-Docker-服務">登入時啟動 WSL 以及 Docker 服務</h2><p>雖說作為開發環境手動執行 Docker 服務也不是什麼問題，在不使用時還可以節省系統資源。但如果是專門用來開發的電腦，登入後就將環境準備好還是比較方便的。WSL 環境中的 Ubuntu 系統沒有支援 Systemd 來自動啟用服務這點，有大牛提出 <a href="https://forum.snapcraft.io/t/running-snaps-on-wsl2-insiders-only-for-now/13033" target="_blank" rel="noopener">可行的方案</a>。雖然高竿但這種作法對於山姆鍋的需求過於複雜，畢竟目的是要啟動服務而不是有盡可能完整的 Systemd 機制。</p><p>山姆鍋的作法是藉為 Windows 允許使用者登入系統時可以自動執行指定腳本的機制來實現啟動 Ubuntu 服務的目的。基本的步驟如下：</p><ol><li>確定您 Ubuntu 環境預設的帳戶已經可以不用密碼 (passwordless) 透過 <code>sudo</code> 執行程式。</li><li>在 Windows C 槽 建立一個目錄用來存放腳本，這裡山姆鍋是放在 “C:\Users\sam\wsl-scripts” 目錄中。</li><li>在上述目錄建立 <code>run-start-services.vbs</code> 以及 <code>start-services.bat</code> 兩個腳本檔案。</li><li>將 <code>run-start-services.vbs</code> 複製到 <code>shell:startup</code> 這個特殊目錄。</li><li>重新啟動 Windows 登入後，驗證 Docker 服務是否成功啟動。</li></ol><p><code>run-start-services.vbs</code> 腳本內容：</p><figure class="highlight vbs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Set</span> WinScriptHost = <span class="built_in">CreateObject</span>(<span class="string">"WScript.Shell"</span>)</span><br><span class="line">WinScriptHost.Run <span class="built_in">Chr</span>(<span class="number">34</span>) &amp; <span class="string">"C:\Users\sam\wsl-scripts\start-services.bat"</span> &amp; <span class="built_in">Chr</span>(<span class="number">34</span>), <span class="number">0</span></span><br><span class="line"><span class="keyword">Set</span> WinScriptHost = <span class="literal">Nothing</span></span><br></pre></td></tr></tbody></table></figure><p><code>start-services.bat</code> 腳本內容：</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wsl.exe sudo service docker start</span><br></pre></td></tr></tbody></table></figure><p>wsl.exe 後面的參數就是要在預設的 WSL 環境 (山姆鍋的是 Ubuntu 18.04) 中執行的指令，所以也可以更換成 WSL 中的一個腳本來同時啟動多個服務。因為，山姆鍋的需求只有啟動 Docker 服務，所以只要執行 <code>sudo service docker start</code> 即可。一旦 Docker 服務啟動，設定好會自動執行 (e.g. restart=always) 的容器也會自動啟動。</p><p>要將 <code>run-start-services.vbs</code> 放到 <code>shell:startup</code> 這個特殊目錄，在 Windows 環境開啟「檔案總管」，在位址列中輸入 <code>shell:startup</code>，將 <code>run-start-services.vbs</code> 複製過來 (不是複製捷徑) 。放在這個 <code>shell:startup</code> 特殊目錄的腳本會在您登入 Windows 系統時自動執行。</p><blockquote><p>注意：因為透過 VBScript 來隱藏命令視窗，<code>shell:startup</code> 目錄中的腳本在登入看到 Windows 桌面時可能還在背景執行，因為第一次執行 wsl.exe 啟動對應的 WSL 環境需要一些時間。</p></blockquote><p>老實說，山姆鍋使用這個方法遇到幾次服務沒有正常啟動，但因為不是必需機制，所以就沒花時間深究。不過，您可以另外參考<a href="https://dev.to/ironfroggy/wsl-tips-starting-linux-background-services-on-windows-login-3o98" target="_blank" rel="noopener">這篇文章</a>的作法，至於該方式是不是真的有效，就需要您自己實驗了。</p><h2 id="小結">小結</h2><p>除了比較節省系統資源外，在 WSL 中執行 Docker 服務也可以避開在「<a href="/post/2020/04/dev-env-docker-wsl2-k3d-vs-code/" title="Docker Desktop for WSL2 容器化開發環境">Docker Desktop for WSL2 容器化開發環境</a>」提到的 k3d 所遇到的問題。由於現在 Windows 環境中並沒有安裝 Docker Desktop。所以，VS Code 的 <code>Remote - Containers</code> 延伸模組並無法運作，這是因為該模組需要使用 Docker 的命令列工具。</p><p>因為上述的問題，陸續在實驗：</p><ol><li>使用瀏覽器 IDE 來取代桌面版的 VS Code。</li><li>安裝 X Server，使用完整 Linux 桌面環境。</li><li>Vim + SpaceVim 另類的終端機 IDE。</li></ol><h2 id="參考資料">參考資料</h2><ol><li><a href="https://stackoverflow.com/questions/23557720/execute-batch-file-without-command-line-visible" target="_blank" rel="noopener">Execute Batch File without Command line visible</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;雖然 Docker Desktop for WSL 利用 WSL 來執行 Linux 容器，一方面提高容器在 Windows 環境的執行效率，一方面也提高記憶體等資源與主機系統的共用程度。雖然相對之前採用完整虛擬機相對節省資源，但對山姆鍋的低配 Surface Pro 來說還是太佔資源。也由於 WSL 2 已經可以直接執行 Docker engine 來支援 Linux 容器的執行，所以決定改採用這個方式來提供 Docker 服務。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Ubuntu" scheme="https://samkuo.me/tag/ubuntu/"/>
    
      <category term="Docker" scheme="https://samkuo.me/tag/docker/"/>
    
      <category term="WSL" scheme="https://samkuo.me/tag/wsl/"/>
    
  </entry>
  
  <entry>
    <title>使用 hexo-browsersync 自動刷新瀏覽器頁面</title>
    <link href="https://samkuo.me/post/2020/05/hexo-browsersync-fix/"/>
    <id>https://samkuo.me/post/2020/05/hexo-browsersync-fix/</id>
    <published>2020-05-01T03:07:46.000Z</published>
    <updated>2020-05-02T02:45:32.549Z</updated>
    
    <content type="html"><![CDATA[<p>使用 Hexo 寫部落格文章時，雖然 VS Code 有 Markdown 的預覽延伸套件，但因為預覽並不支援主題所使用的 <code>image</code> 標籤，在發布前還是需要在瀏覽器看實際呈現的結果。雖然知道 Hexo 有 hexo-browsersync 以及 hexo-livereload 插建可以利用，但按照說明一直無法設定成功。</p><a id="more"></a><a class="fancybox" href="markdown-preview.png" title=""><img class="image" src="markdown-preview.png" alt=""></a><p>直到昨天再次嘗試找問題時，發現 <code>hexo server</code> 回傳的網頁內容不完整。所以，當初無法正常刷新頁面的原因似乎跟 Hexo 在文章長度太長時沒有正確傳回完整 HTML 內容，導致 Browser sync 插入的 JavaScript 腳本沒有被執行，自然就無法刷新頁面。因為在預覽文章內容時呈現的結果是正確的，就沒有想到 HTML 原始碼被截斷的可能。幸好，知道了可能原因就來動手解決吧！</p><p>解法其實也很簡單：在 Hexo 的 _config.yml 檔案中，<code>server</code> 區段加入 <code>compress: true</code> 如下所示：</p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">server:</span></span><br><span class="line">  <span class="attr">compress:</span> <span class="literal">true</span></span><br></pre></td></tr></tbody></table></figure><p>雖然不知道是否根本解決，但到目前為止瀏覽器都能自動刷新了。</p><h2 id="參考資料">參考資料</h2><ul><li><a href="https://cloud.tencent.com/developer/article/1600749" target="_blank" rel="noopener">hexo 中文文章渲染错误的 bug 解决</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;使用 Hexo 寫部落格文章時，雖然 VS Code 有 Markdown 的預覽延伸套件，但因為預覽並不支援主題所使用的 &lt;code&gt;image&lt;/code&gt; 標籤，在發布前還是需要在瀏覽器看實際呈現的結果。雖然知道 Hexo 有 hexo-browsersync 以及 hexo-livereload 插建可以利用，但按照說明一直無法設定成功。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="hexo" scheme="https://samkuo.me/tag/hexo/"/>
    
      <category term="blog" scheme="https://samkuo.me/tag/blog/"/>
    
  </entry>
  
  <entry>
    <title>Docker Desktop for WSL2 容器化開發環境</title>
    <link href="https://samkuo.me/post/2020/04/dev-env-docker-wsl2-k3d-vs-code/"/>
    <id>https://samkuo.me/post/2020/04/dev-env-docker-wsl2-k3d-vs-code/</id>
    <published>2020-04-22T03:32:25.000Z</published>
    <updated>2020-04-30T02:56:36.143Z</updated>
    
    <content type="html"><![CDATA[<!-- excerpt --><h2 id="前言">前言</h2><p>山姆鍋主要的開發機是 15 吋的 MacBook Pro, 但為了工作方便攜帶也買了一台 Surface Pro。當初為了能夠在這台 Surface Pro 執行 Docker Desktop, 還特地選了 Windows 10 Professtional 版本 (支援 Hyper-V 虛擬技術)，但 Surface Pro 記憶體只有 4GB, 導致就算 Docker Desktop 跑起來了，也沒有多少資源可以用於開發用途，只能用來進行遠端運維工作。最近發現 Docker Desktop Edge 版本支援 WSL 2 作為後端，除了執行效能提高，記憶體也可以跟其它程式共用，因此興起重新折騰這台 Surface Pro 的念頭。</p><p>本文旨在說明山姆鍋的本機工作環境的主要組成跟各個元件的用途，並非如何安裝的步驟說明。</p><h2 id="目標">目標</h2><p>由於工作大多是 Web 應用相關，也習慣採用容器化持續部署方式，山姆鍋希望也以容器化開發環境來使用工作機。 此工作環境需要滿足下列目標：</p><ul><li>必須足夠輕量化：山姆鍋的 Surface Pro CPU 不夠強，記憶體也只有 4GB，因此採用的方案需要可以在此限制下執行。</li><li>支援 Kubernetes: Kubernetes 是 Web 應用的部署環境，需要能夠直接在此工作環境運行。</li><li>接近 MacBook Pro 上的開發模式：由於已經習慣 MacBook 的開發環境，自然希望兩者越接近越好。</li></ul><h2 id="基本環境">基本環境</h2><p>本文所提的容器化開發環境，需要工作機已經安裝好支援 WSL 2 的 Windows 系統。 山姆鍋採用的是 Windows 10 Pro 測試人員計畫特別版本。雖然 WSL 2 也有採用虛擬化技術，但 WSL 2 所運行的輕量虛擬機跟 Windows 系統進行效能優化以及高度整合，在效能以及操作便利性上不是直接使用 Hyper-V、Virtualbox 等虛擬機可以比擬。</p><p>WSL 2 相關的安裝說明可以參考 <a href="https://docs.microsoft.com/zh-tw/windows/wsl/wsl2-install" target="_blank" rel="noopener">WSL 2 的安裝指示</a>。</p><h2 id="容器化開發環境">容器化開發環境</h2><p>容器化開發環境是以容器來作為開發、建置與發行的主要技術，特別適用於 Web 應用的開發。這個容器化開發環境主要由下面元件組成：</p><h3 id="Ubuntu-18-04-WSL-發行版">Ubuntu 18.04 WSL 發行版</h3><p>從 Windows Store 上安裝 Ubuntu 18.04 的發行版本。 WSL 2 也支援其它 Linux 發行版本，但 Ubuntu 使用較廣泛也是山姆鍋比較熟悉的系統。這個 WSL 2 環境負責運行容器以及作為主要命令列工作環境。</p><h3 id="Docker-Desktop-Edge">Docker Desktop Edge</h3><p>是整個容器化開發的主要技術核心，提供容器的建置與運行。藉由 WSL 2 的支援讓 Linux 容器可以在 Windows 系統上接近原生的效能執行。由於 Ubuntu 18.04 WSL 不支援 Systemd, 所以如果一啟動就需要的服務也是以容器方式執行，例如：使用容器執行私有的 registry 服務來存放容器映像檔。</p><p>相關連結：<a href="https://docs.docker.com/docker-for-windows/wsl-tech-preview/" target="_blank" rel="noopener">Docker Desktop WSL 2 Backend</a></p><div class="figure " style="width:;"><a class="fancybox" href="docker-desktop-edge.png" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="docker-desktop-edge.png" alt=""></a></div><h3 id="Visual-Studio-Code">Visual Studio Code</h3><p>除非需要開發行動應用程式，不然 VS Code 就是山姆鍋預設的整合開發環境。VS Code 的 Remote development 套件讓 VS Code 可以使用容器方式來管理開發環境，如此開發者不用再為了不同專案安裝不同版本的程式語言跟環境。</p><p>VS Code 是在 Windows 環境中安裝，需要確定 VS Code 執行檔在 <code>PATH</code> 環境變數中。</p><h3 id="Remote-Containers-擴充套件">Remote - Containers 擴充套件</h3><p>新加入一個專案，工程師往往需要安裝不同工具、套件才能真正開始編譯跟建置程式碼，如果可以讓這樣的準備工作自動化就能夠有效減低進入門檻。VS Code 的 Remote - Containers 套件提供使用容器來作為開發環境，所需要的工具、語言套件都在容器內提供，開發者工作環境不用再安裝各種不同版本的工具與執行環境。由於以描述檔方式紀錄開發環境如何組成與建置，這些描述檔隨同專案程式碼發佈，使用 VS Code 開啟時便會自動建置所需的開發用容器。雖然使用容器作為開發環境可以避免污染工作主機，但缺點是需要花費額外建置容器時間。</p><p>相關參考：<a href="https://code.visualstudio.com/docs/remote/containers" target="_blank" rel="noopener">Developing inside a Container</a></p><h3 id="Remote-WSL-擴充套件">Remote - WSL 擴充套件</h3><p>此 VS Code 擴充套件讓開發者可以使用 WSL Linux 發行版本作為完整的開發環境。有了此擴充套件，當從 WSL 環境中執行 <code>code</code> 指令時，會啟動 Windows 版的 VS Code, 而 VS Code 會自動連到 WSL，並使用當下目錄作為工作空間 (workspace)，開啟 VS Code terminal 也是執行 WSL 預設的 shell。</p><p>相關參考：<a href="https://code.visualstudio.com/docs/remote/wsl" target="_blank" rel="noopener">Developing in WSL</a></p><p>下圖是 VS Code 連結到 WSL 的截圖：</p><div class="figure " style="width:;"><a class="fancybox" href="vs-code-wsl.png" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="vs-code-wsl.png" alt=""></a></div><h3 id="K3S">K3S</h3><p>由 Rancher 所開發的輕量化 Kubernetes 叢集發行版本，在 <a href="/post/2020/04/multipass-k3s-kubernetes-dev-env/">運用 Multipass 與 K3S 建立 Kubernetes 測試環境</a> 一文中，山姆鍋有對 K3S 的簡短介紹。 相對於官方的 Kubernetes 發行版，K3S 對於記憶體的需求低，主要 (master) 節點只需要 512MB 記憶體便可以正常運行，因此山姆鍋選擇 K3S 作為開發環境中的 Kubernetes 部署用途。</p><div class="figure " style="width:;"><a class="fancybox" href="k3s-k3d.png" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="k3s-k3d.png" alt=""></a></div><h3 id="K3D">K3D</h3><p>在開發環境，每個專案的 Kubernetes 部署環境組態往往不同，需要個別分開。為了能夠快速建置跟管理各個專案的 K8S 叢集，需要採用 K3D 這個命令列工具。 K3D 將 K3S 叢集部署在一個 Docker 容器中執行，可以同時管理跟執行不同專案的 K3S 環境。</p><blockquote><p>K3D 命令列工具需要在 Windows 以及 WSL 環境中都安裝。理想上，K3D 只需要在 WSL 環境安裝即可，但從 WSL 中執行創建 (create) K3S 叢集時後遇到 <code>Permission denied</code> 的錯誤導致無法成功 (同樣指令從 Windows 命令列可以正常)。同樣地，在 WSL 中執行 <code>k3d get-kubeconfig</code> 取得的 kubeconfig 設定檔，在執行 <code>kubectl</code> 指令時會出現 <code>certificate signed by unknown authority</code> 的錯誤。 <code>k3d</code> 在 WSL 的其它操作都可以正常使用，所以在創建 K3S 叢集跟產生 <code>kubeconfig</code> 檔案時，需要使用 Windows 版的 K3D 命令列工具。 由於 WSL 命令列可以直接啟動 Windows 程式，所以在 WSL 環境中，將 <code>k3d</code> 指令換成 <code>k3d.exe</code> 就可以。</p></blockquote><h3 id="Windows-Terminal">Windows Terminal</h3><p>Windows 內建支援的終端機模擬器很陽春，通常會換用其它模擬器，如 wsltty, Windows Terminal, ConEmu, Hyper 等等。 山姆鍋在建置此工作環境時，試過 wsltty 跟 Windows Terminal, 選用 Windows Terminal 主要是因為同時可以支援 「命令列提示字元」、Power Shell 以及 WSL。雖然希望主要都在 Linux 環境下操作命令，但還是不時需要開啟 Windows 命令列來執行一些指令。</p><p>有了好的終端機模擬器，自然跟 MacBook Pro 上一樣選用 Zsh + Oh My Zsh 來作為命令列操作介面。下圖是 Windows Terminal 截圖，畫面顯示的是 Ubuntu 的 Zsh 命令令操作介面，<code>cmd</code> 分頁則是 Windows 的 「命令提示字元」。</p><div class="figure " style="width:;"><a class="fancybox" href="windows-terminal.png" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="windows-terminal.png" alt=""></a></div><blockquote><p>注意：從 Windows Store 上面安裝的 Windows Terminal Preview 版本會有無法輸入中文的問題，這裡的 Windows Terminal 是透過 <a href="https://scoop.sh/" target="_blank" rel="noopener">Scoop</a> 安裝。</p></blockquote><blockquote><p>2020/4/30 Edit: 後來重新從 Windows Store 安裝 Windows Terminal Preview 又可以正常顯示與輸入中文。建議優先使用 Windows Store 的版本。</p></blockquote><h2 id="為何不直接裝-Ubuntu">為何不直接裝 Ubuntu?</h2><p>雖然有在 Surface Pro 上直接安裝 Ubuntu 系統的想法，但其實還是蠻需要這台 Surface Pro 可以執行一些 Windows 應用，所以折衷採用 Windows Subsystem for Linux (WSL)。 WSL 是微軟讓 Windows 系統可以不用虛擬機直接執行原生 Linux 程式的技術，WSL 1 雖然可以稱職地執行 Ubuntu 多數的命令列程式，對於運維是綽綽有餘，但由於 I/O 效能太差，拿來開發明顯效率不佳。 WSL 2 採用輕量虛擬化技術重新設計架構，直接在 WSL 中執行 Linux 核心 (WSL 1 只是轉換系統呼叫到 Windows 核心) 來達到與現有 Linux 更高的相容度 (如 Docker 已經可以原生在 WSL 2 中執行)，更重要的是 WSL2 預計只需要 Windows 10 Home 版本就可以支援。雖然聽起來很美好，但是 WSL2 還沒正式發行，需要參加 Windows Insider 計畫才能取得；Docker Desktop 也需要 Edge 版本才有支援 WSL 2。由於不是主要工作環境，拿來試試新技術也無妨啦！</p><h2 id="小結">小結</h2><p>當初山姆鍋在推行全端容器化開發時遇到的主要問題是多數的工程師的 Windows 系統都不具備 Hyper-V 虛擬機功能，也就是無法直接執行 Docker Desktop。使用 VirtualBox 效能不佳且耗用系統資源，在前端工程師的推廣上遭遇失敗。隨著技術的演進，山姆鍋又看到一線曙光，也希望 Docker Desktop for WSL2 的正式推出可以讓容器化技術更加地普及。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Surface Pro 跑得動 Docker + Kubernetes? 採用輕量化虛擬技術加上特別的 K8S 發行套件，答案應該是可行的。本文山姆鍋告訴您可以採用哪些組件來達成。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Kubernetes" scheme="https://samkuo.me/tag/kubernetes/"/>
    
      <category term="Docker" scheme="https://samkuo.me/tag/docker/"/>
    
      <category term="WSL2" scheme="https://samkuo.me/tag/wsl2/"/>
    
      <category term="K3S" scheme="https://samkuo.me/tag/k3s/"/>
    
      <category term="K3D" scheme="https://samkuo.me/tag/k3d/"/>
    
      <category term="Container" scheme="https://samkuo.me/tag/container/"/>
    
      <category term="容器" scheme="https://samkuo.me/tag/%E5%AE%B9%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>運用 Multipass 與 K3S 建立 Kubernetes 測試環境</title>
    <link href="https://samkuo.me/post/2020/04/multipass-k3s-kubernetes-dev-env/"/>
    <id>https://samkuo.me/post/2020/04/multipass-k3s-kubernetes-dev-env/</id>
    <published>2020-04-06T01:21:18.000Z</published>
    <updated>2020-04-06T04:30:48.336Z</updated>
    
    <content type="html"><![CDATA[<!-- excerpt --><div class="figure " style="width:;"><img class="fig-img" src="https://rancher.com/docs/img/rancher/k3s-architecture-single-server.png" alt=""></div><h2 id="前言">前言</h2><p>本文目的在本地主機建構一個單節點的 Kubernetes 叢集環境以方便快速測試。雖然 Minikube 相當方便，但採用 Multipass 擁有更大彈性來客製化作業系統 (Ubuntu)，例如：安裝額外系統套件。幸運的是，Rancher Labs (開發 Rancher 的公司) 提供一個可以用在生產環境的精簡 Kubernetes 發行版本 K3S，重點是 “精簡” 以及 “生產環境”。所以，本文的另一個目的就是讓開發、測試與生產環境都可以使用相同的 K3S。</p><h2 id="Multipass-簡介">Multipass 簡介</h2><p>根據官網說明，Multipass 是一個利用現有平台 (Windows、OS X、Linux) 原生虛擬機技術，在個人工作機上建置一個迷你雲 (mini-cloud)。 在 Windows 系統， Multipass 使用 Hyper-V、OS X 預設使用 Hyperkit 、而在 Linux 系統則預設使用 KVM 來作為虛擬化方案。如同 Docker Desktop 提供方便的工具來管理容器一般，Multipass 則是提供方便的工具來管理多個虛擬機，足夠應付大部分應用情境，如果需要本機較完整的虛擬機自動管理方案，山姆鍋建議使用 Vagrant。</p><h2 id="Multipass-安裝">Multipass 安裝</h2><p>本文假設使用的本地環境是 OS X, 對於其它系統請參考 Multipass <a href="https://multipass.run/docs" target="_blank" rel="noopener">官方文件</a>。</p><p>在已經安裝 Homebrew 的 OS X 的系統，只需要在終端機執行下列指令就可以安裝 Multipass:</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ brew cask install multipass</span><br></pre></td></tr></tbody></table></figure><h2 id="K3S-簡介">K3S 簡介</h2><p>K3S 是 Rancher Labs 公司針對邊緣計算 (edge computing)、IoT 系統、K8S CI/CD 所推出的精簡 K8S 發行版本，特別支援 ARM 處理器架構，所以可以執行在 Raspberry 等單板電腦上。由於移除 K8S 中雲端環境的支援以及使用 SQLite 取代 etcd 等來將符合標準的 K8S 系統縮小到一個執行檔內。</p><p>對於 K3S 的更好的中文介紹，可以參考 <a href="https://bestsamina.github.io/posts/2019-10-10-k3s-intro-and-play/" target="_blank" rel="noopener">邊緣運算之容器管理工具 - K3s 之介紹與玩耍</a> 這篇文章。</p><h2 id="本地-K8S-環境安裝">本地 K8S 環境安裝</h2><h3 id="建構虛擬機">建構虛擬機</h3><p>首先使用 Multipass 建構一個名為 k3s 的虛擬機：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ multipass launch -n k3s</span><br></pre></td></tr></tbody></table></figure><p>可以看到 <code>Launched: k3s</code> 顯示訊息即表示虛擬機建構完成。</p><blockquote><p>預設是 1GB 的記憶體、5GB 的硬碟空間，如果需要調整可以參考 Multipass 文件。</p></blockquote><h3 id="安裝-K3S">安裝 K3S</h3><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ multipass <span class="built_in">exec</span> k3s -- bash -c <span class="string">"curl -sfL https://get.k3s.io | K3S_KUBECONFIG_MODE=644 sh -"</span></span><br></pre></td></tr></tbody></table></figure><p>可以看到類似下面的輸出訊息:</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[INFO]  Finding latest release</span><br><span class="line">[INFO]  Using v1.17.4+k3s1 as release</span><br><span class="line">[INFO]  Downloading hash https://github.com/rancher/k3s/releases/download/v1.17.4+k3s1/sha256sum-amd64.txt</span><br><span class="line">[INFO]  Downloading binary https://github.com/rancher/k3s/releases/download/v1.17.4+k3s1/k3s</span><br><span class="line">[INFO]  Verifying binary download</span><br><span class="line">[INFO]  Installing k3s to /usr/local/bin/k3s</span><br><span class="line">[INFO]  Creating /usr/local/bin/kubectl symlink to k3s</span><br><span class="line">[INFO]  Creating /usr/local/bin/crictl symlink to k3s</span><br><span class="line">[INFO]  Creating /usr/local/bin/ctr symlink to k3s</span><br><span class="line">[INFO]  Creating killall script /usr/local/bin/k3s-killall.sh</span><br><span class="line">[INFO]  Creating uninstall script /usr/local/bin/k3s-uninstall.sh</span><br><span class="line">[INFO]  env: Creating environment file /etc/systemd/system/k3s.service.env</span><br><span class="line">[INFO]  systemd: Creating service file /etc/systemd/system/k3s.service</span><br><span class="line">[INFO]  systemd: Enabling k3s unit</span><br><span class="line">Created symlink /etc/systemd/system/multi-user.target.wants/k3s.service → /etc/systemd/system/k3s.service.</span><br><span class="line">[INFO]  systemd: Starting k3s</span><br></pre></td></tr></tbody></table></figure><h3 id="設定-Kubectl">設定 Kubectl</h3><p>雖然可以使用 <code>multipass shell k3s</code> 進入虛擬機環境執行 kubectl, 但使用本地的 kubectl 來操作 K8S 還是比較符合需求。</p><p>本文假設本地主機已經有安裝 kubectl 命令列工具，如果還沒有安裝，可參考<a href="https://docs.aws.amazon.com/zh_tw/eks/latest/userguide/install-kubectl.html" target="_blank" rel="noopener">這篇文章</a>。</p><p>在終端機執行下列指令：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ multipass info k3s</span><br></pre></td></tr></tbody></table></figure><p>顯示的訊息中，<code>IPv4</code> 那行即為虛擬機的 IP 位址，透過這個位址本地主機可以跟虛擬機進行連線。本文虛擬主機的 IP 位址為 $K3S_NODE_IP。</p><p>執行下列指令將 K3S 的 kubeconfig 檔案複製到本機：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ multipass <span class="built_in">exec</span> k3s sudo cat /etc/rancher/k3s/k3s.yaml &gt; ~/.kube/k3s.yaml</span><br></pre></td></tr></tbody></table></figure><p>由於 k3s.yaml 使用 127.0.0.1 來跟 API server 溝通，需要改成虛擬機的真實 IP 位址才能正常存取。可以使用文件編輯器來將 127.0.0.1 更換成 ＄K3S_NODE_IP，或者使用下列指令：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">＄sed -i <span class="string">''</span> <span class="string">"s/127.0.0.1/<span class="variable">$K3S_NODE_IP</span>/"</span> ~/.kube/k3s.yaml</span><br></pre></td></tr></tbody></table></figure><p>驗證 kubectl 是否可正常連線，執行下列指令：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl --kubeconfig ~/.kube/k3s.yaml get nodes</span><br></pre></td></tr></tbody></table></figure><p>如果看到類似下面輸出，則表示單節點 K8S 環境正常運行中：</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">NAME   STATUS   ROLES    AGE   VERSION</span><br><span class="line">k3s    Ready    master   27m   v1.17.4+k3s1</span><br></pre></td></tr></tbody></table></figure><p>為了方便操作，可以設定 <code>KUBECONFIG</code> 環境變數，</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> KUBECONFIG=~/.kube/k3s.yaml</span><br></pre></td></tr></tbody></table></figure><p>如此，就有一個基本的 Kubernetes 運行環境了！</p><p>下面是將上述步驟自動化的腳本 (<a href="http://k3s-launch.sh" target="_blank" rel="noopener">k3s-launch.sh</a>)：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">multipass launch -n k3s</span><br><span class="line"></span><br><span class="line">multipass <span class="built_in">exec</span> k3s -- bash -c <span class="string">"curl -sfL https://get.k3s.io | K3S_KUBECONFIG_MODE=644 sh -"</span></span><br><span class="line"></span><br><span class="line">multipass <span class="built_in">exec</span> k3s sudo cat /etc/rancher/k3s/k3s.yaml &gt; ~/.kube/k3s.yaml</span><br><span class="line"></span><br><span class="line">K3S_NODE_IP=$(multipass info k3s | grep IPv4 | awk <span class="string">'{print $2}'</span>)</span><br><span class="line"></span><br><span class="line">sed -i <span class="string">''</span> <span class="string">"s/127.0.0.1/<span class="variable">$K3S_NODE_IP</span>/"</span> ~/.kube/k3s.yaml</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"K3s cluster is ready !"</span></span><br><span class="line"><span class="built_in">echo</span></span><br></pre></td></tr></tbody></table></figure><h2 id="解除安裝">解除安裝</h2><p>如果要清除 K3S 虛擬機，只需要執行下列指令：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ multipass delete k3s</span><br><span class="line">$ multipass purge</span><br></pre></td></tr></tbody></table></figure><h2 id="小結">小結</h2><p>本文雖然只說明單節點 K8S 叢集的建置，但透過 Multipass + K3S 其實可以建置多節點，甚至高可用的 K8S 叢集。在第一次啟用上，Multipass + K3S 也比 Minikube 明顯稍快，畢竟 Minikube 需要下載以及執行更多元件。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;雖然已經有 Docker Desktop、Minikube 等可以提供 K8S 本機的測試環境，但最近才發現 Canonical 公司 (Ubuntu 的發行商) 提供 Multipass 這個輕量級的跨平台虛擬機管理方案，標榜跟 Docker Desktop 一樣容易使用。由於 Ubuntu 也是山姆鍋偏好的部署環境作業系統，如果能夠從開發、測試到生產環境都使用相同的作業系統，也許是個好主意。因此，嘗試使用 Multipass 來建置 K8S 本地開發、測試環境。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="K3S" scheme="https://samkuo.me/tag/k3s/"/>
    
      <category term="Container" scheme="https://samkuo.me/tag/container/"/>
    
      <category term="multipass" scheme="https://samkuo.me/tag/multipass/"/>
    
      <category term="K8S" scheme="https://samkuo.me/tag/k8s/"/>
    
  </entry>
  
  <entry>
    <title>Web 新創也該使用 Kubernetes</title>
    <link href="https://samkuo.me/post/2020/04/kubernetes-is-for-startup/"/>
    <id>https://samkuo.me/post/2020/04/kubernetes-is-for-startup/</id>
    <published>2020-04-03T00:12:13.000Z</published>
    <updated>2020-05-04T00:15:12.680Z</updated>
    
    <content type="html"><![CDATA[<p>導入 Kubernetes 的門檻不低，在過去我並不建議新創團隊一開始就採用。隨著雲端託管的 K8S 服務越來越普及，本地開發、測試工具與環境容易取得，加上自建與維運一個 K8S 叢集的解決方案越加成熟，再再都顯示使用 K8S 作為應用部署平台的好處已超過導入的成本。時至今日，對於開發網路軟體產品的團隊，我已經會建議一開始就是以 K8S 作為預設的部署環境，除了利用 K8S 的高可用性與擴充性架構外，也讓網路應用可以更容易移植 (portable) 到不同的基礎設施。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;導入 Kubernetes 的門檻不低，在過去我並不建議新創團隊一開始就採用。隨著雲端託管的 K8S 服務越來越普及，本地開發、測試工具與環境容易取得，加上自建與維運一個 K8S 叢集的解決方案越加成熟，再再都顯示使用 K8S 作為應用部署平台的好處已超過導入的成本。時至今
      
    
    </summary>
    
    
    
      <category term="Kubernetes" scheme="https://samkuo.me/tag/kubernetes/"/>
    
      <category term="Web Startup" scheme="https://samkuo.me/tag/web-startup/"/>
    
  </entry>
  
  <entry>
    <title>一個故事說明軟體架構的必要性</title>
    <link href="https://samkuo.me/post/2020/03/why-sotfware-architecture-is-necessary-by-story/"/>
    <id>https://samkuo.me/post/2020/03/why-sotfware-architecture-is-necessary-by-story/</id>
    <published>2020-03-23T06:15:06.000Z</published>
    <updated>2020-03-23T09:32:35.458Z</updated>
    
    <content type="html"><![CDATA[<p>在山姆鍋早期的職業生涯，還在擔任軟體工程師的時候，發生的一件事讓山姆鍋體驗到要讓整個團隊的開發成為一個完整可順利運行的系統，缺乏架構真的困難重重。</p><a id="more"></a><p>當時團隊連同技術主管有四個人，在開發的軟體是個 Java web 應用，使用的是很常見的三層架構：web、app 跟 data。這個軟體一開始的架構就剛好是四個模組，分別為「前端 UI」、「後台 UI」、「核心模組」以及「整合模組」(這些名稱是山姆鍋現在編撰的，在當時內部鐵定不是這樣稱呼)。山姆鍋負責核心模組，另外兩位工程師各自負責前端跟後台，而技術主管則負責神秘的整合模組。之所以神秘，主管分別跟三位工程師各自設計自己負責的模組介面，然後由他負責開發整合模組，這也是為何山姆鍋稱主管負責的模組叫做整合模組。而之所以神秘的原因是：山姆鍋連同另外兩位工程師從來就不知道整合模組如何運作。在前端、後台以及核心模組開發完成後(只剩整合)，山姆鍋了解到現在的模組設計的介面根本就無法整合，多次在會議中提出這問題，請主管跟我們說明如何整合，主管一再說我們不用管也不用擔心，他會負責處理。就這樣一個月過去了，依然得到同樣的說法。由於專案時程僅剩一個多月，如果再沒有可以運行測試的軟體，專案鐵定會延遲交付了！莫可奈何下，山姆鍋直接跟主管攤牌：現在就需要他完成整合，不然就承認他做不到 (由於當時是新創公司，公司有些主管甚至還是在學研究生)。事後才知道，雖然主管是資工本科系畢業，但程式開發能力根本不行，當時 CEO 只因為他是台清交畢業就指派他作為主管，但他卻好面子不想承認又想要有表現實際參與開發工作，這導致專案前期的開發很多部分要重做，也導致後來整個月山姆鍋每天都在加班。</p><p>上述的故事可能有點極端，但卻是山姆鍋遇到的真實案例。重點是：一旦一個軟體系統需要由多人來一起開發跟維運，就需要有人設計跟決定架構，參與的成員最好也能夠了解整個架構，了解自己負責的元件在系統中的位置以及扮演的角色。在這個案例中，還只是少數成員且相對簡單的架構都可以因為不清楚架構而導致進度停擺。所以，在實際動手寫程式之前，先確定好架構再說。即使是白板上畫的圖，只要能夠跟團隊成員溝通清楚都比打迷糊仗好。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在山姆鍋早期的職業生涯，還在擔任軟體工程師的時候，發生的一件事讓山姆鍋體驗到要讓整個團隊的開發成為一個完整可順利運行的系統，缺乏架構真的困難重重。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="software architecture" scheme="https://samkuo.me/tag/software-architecture/"/>
    
  </entry>
  
  <entry>
    <title>在 Ubuntu 上部署適合上線的單機 NodeBB 論壇服務</title>
    <link href="https://samkuo.me/post/2020/03/install-nodebb-digitalocean-production/"/>
    <id>https://samkuo.me/post/2020/03/install-nodebb-digitalocean-production/</id>
    <published>2020-03-22T06:00:59.000Z</published>
    <updated>2020-03-23T02:37:15.282Z</updated>
    
    <content type="html"><![CDATA[<p>本文山姆鍋分享如何安裝與設定一個 NodeBB 論壇的正式生產環境 (production environment)。由於整個環境不只包含 NodeBB 本身，會從主機系統的開始設定開始到 Nginx web 服務。安裝過程參考了多篇文章，對於特定元件的安裝細節會直接連結到對應的教學文章，本文盡量只做重點說明。</p> <a id="more"></a><div class="alert info no-icon"><p>歡迎您加入 <a href="https://developers.tw" target="_blank" rel="noopener">#Developers.TW</a> ，A.K.A. ＃呆丸開發者。</p></div><h2 id="安裝目標">安裝目標</h2><p>本文是以 <a href="https://developers.tw" target="_blank" rel="noopener">#Developers.TW</a> 作為實際案例，並以符合需求的最少安裝為目標。選擇性的元件，如 iframely 網頁內嵌剖析或者 Solr 搜尋服務並不在本文說明。因為目標是可用在正式上線的最小安裝，擴充性、可用性等等自然也就先不要求了。</p><p>下圖是部署完成後粗略的系統架構圖：</p><div class="figure " style="width:;"><a class="fancybox" href="nodebb-deployment.jpg" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="nodebb-deployment.jpg" alt=""></a></div><h2 id="準備工作">準備工作</h2><p>底下是一些 NodeBB 論壇安裝設定需要的前置需求：</p><ol><li>有 NodeBB 論壇的專屬域名或子域名，像 #<a href="http://Developers.TW" target="_blank" rel="noopener">Developers.TW</a> 的域名是 <a href="http://developers.tw" target="_blank" rel="noopener">developers.tw</a>。</li><li>域名服務器已經設定完畢。本文是採用 CloudFlare 作為 DNS 以及 CDN 服務供應商。</li><li>讀者知道如何設定域名的 DNS 紀錄。</li><li>部署使用的工作機 (筆電或者 PC) 已經有 SSH 登入的金鑰對 (key pair)。</li></ol><h2 id="主機系統">主機系統</h2><p>對於經濟實惠又需要完整系統的部署環境，山姆鍋通常都會選用 DigitalOcean 的 VPS 虛擬私有伺服器，這次也不例外，選用一個標準型 1GB 記憶體、1 核 vCPU 的 Droplet 作為部署環境。</p><p>註冊 DigitalOcean 帳戶以及建立一個 Droplet 可以參考 <a href="https://cyku.tw/digital-ocean/" target="_blank" rel="noopener">Digital Ocean: 申請自己的虛擬主機伺服器</a>。</p><h3 id="基本環境-Ubuntu-18-04">基本環境 (Ubuntu 18.04)</h3><table><thead><tr><th>項目</th><th>方案</th></tr></thead><tbody><tr><td>主機環境</td><td> DigitalOcean Droplet</td></tr><tr><td> 主機組態</td><td> 1 core vCPU, 1GB RAM, 25GB SSD</td></tr><tr><td> 作業系統</td><td> Ubuntu 18.04 64-bit</td></tr></tbody></table><h3 id="郵件寄送">郵件寄送</h3><p>強烈建議使用雲端電子信件寄送服務，不要在主機自行安裝 Postfix, Exim 等郵件軟體。現在雲端郵件寄送服務功能完整、成功送達率較高，又有每月免費使用額度。#<a href="http://Developers.TW" target="_blank" rel="noopener">Developers.TW</a> 使用的是 SendGrid 提供的郵寄服務，只是因為山姆鍋有使用經驗，讀者可以選擇自己熟悉的服務。</p><p>不管採用哪個服務，需要取得下列郵件寄送服務的網路參數：</p><table><thead><tr><th>項目</th><th>說明</th></tr></thead><tbody><tr><td> SMTP 伺服器位址</td><td> IP 或域名</td></tr><tr><td> SMTP 監聽埠</td><td>如 487</td></tr><tr><td>SMTP 登入名稱</td><td> SendGrid 使用 ‘apikey’ 作為登入名稱</td></tr><tr><td> SMTP 登入密碼</td><td>從 SendGrid 申請的 api key 內容</td></tr></tbody></table><p>有了雲端郵件寄送服務後，要讓主機系統可以寄出信件，尚須安裝與設定下列套件：</p><ul><li>mailutils</li><li>ssmtp</li></ul><p>使用下列指令安裝：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install mailutils ssmtp</span><br></pre></td></tr></tbody></table></figure><p>ssmtp 需要根據雲端郵寄服務提供的網路參數來設定，底下是 <code>/etc/ssmtp/ssmtp.conf</code> 檔案的內容：</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">#</span><br><span class="line"># Config file for sSMTP sendmail</span><br><span class="line">#</span><br><span class="line"># The person who gets all mail for userids &lt; 1000</span><br><span class="line"># Make this empty to disable rewriting.</span><br><span class="line">root=sam@example.com   # 管理者的 email</span><br><span class="line"></span><br><span class="line"># The place where the mail goes. The actual machine name is required no </span><br><span class="line"># MX records are consulted. Commonly mailhosts are named mail.domain.com</span><br><span class="line">mailhub=smtp.sendgrid.net:587 # 雲端郵件寄送服務提供接口</span><br><span class="line"></span><br><span class="line"># Where will the mail seem to come from?</span><br><span class="line">#rewriteDomain=</span><br><span class="line">rewriteDomain=developers.tw  ＃改寫收件人看到的郵件來源域名</span><br><span class="line"></span><br><span class="line"># The full hostname</span><br><span class="line">hostname=nodebb-test   ＃ 主機名稱</span><br><span class="line"></span><br><span class="line"># Are users allowed to set their own From: address?</span><br><span class="line"># YES - Allow the user to specify their own From: address</span><br><span class="line"># NO - Use the system generated From: address</span><br><span class="line">#FromLineOverride=YES</span><br><span class="line"></span><br><span class="line">AuthUser=apikey             # SMTP 登入名稱</span><br><span class="line">AuthPass=xxxxxxxxxx         # SMTP 登入密碼</span><br><span class="line"></span><br><span class="line">UseSTARTTLS=YES</span><br><span class="line">UseTLS=YES</span><br></pre></td></tr></tbody></table></figure><p>餐考文章：</p><ul><li><a href="https://blog.gtwang.org/linux/linux-send-mail-command-using-ssmtp-and-gmail/" target="_blank" rel="noopener">Linux 使用 SSMTP 與 GMail 以指令或程式自動寄信教學</a> 。</li></ul><h3 id="安全強化">安全強化</h3><p>完成主機系統的基本安裝後，作為網路服務主機，主機安全性也不容輕忽。</p><h4 id="SSH">SSH</h4><p>底下是一些安全強化重點 (只是基本):</p><ol><li>只允許使用憑證 SSH 遠端登入主機，禁用密碼。</li><li>SSH 不允許直接以 root 帳戶登入。</li><li>(選擇性) 更改 SSH 服務的監聽埠 (port)，例如：939：這個不會增加多少安全性，但可以有效減少系統日誌的被攻擊的紀錄。</li></ol><p>參考文章：</p><ul><li><a href="https://www.digitalocean.com/community/questions/best-practices-for-hardening-new-sever-in-2017" target="_blank" rel="noopener">Best practices for hardening new sever in 2017</a></li><li></li></ul><h4 id="自動更新安全修補">自動更新安全修補</h4><p>當主機系統被發現有安全漏洞時，山姆鍋希望能夠自動更新修補程式。採考此文章 <a href="https://phoenixnap.com/kb/automatic-security-updates-ubuntu" target="_blank" rel="noopener">How To Setup And Enable Automatic Security Updates On Ubuntu</a> 。</p><h3 id="安裝-unattended-upgrade-套件">安裝 unattended-upgrade 套件</h3><p>使用下列指令安裝 unattended-upgrade 套件：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt install unattended-upgrades</span><br></pre></td></tr></tbody></table></figure><p><code>unattended-upgrades</code> 的設定檔為 <code>/etc/apt/apt.conf.d/50unattended-upgrades</code>，山姆鍋直接使用預設值。如果需要增加自動更新的套件庫 (repository)，可以用文字編輯器修改此文件，移除對應行前 <code>//</code> 註解符號。</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Unattended-Upgrade::Allowed-Origins {</span><br><span class="line">        <span class="string">"<span class="variable">${distro_id}</span>:<span class="variable">${distro_codename}</span>"</span>;</span><br><span class="line">  <span class="string">"<span class="variable">${distro_id}</span>:<span class="variable">${distro_codename}</span>-security"</span>;</span><br><span class="line">  // Extended Security Maintenance; doesn<span class="string">'t necessarily exist for</span></span><br><span class="line"><span class="string">  // every release and this system may not have it installed, but if</span></span><br><span class="line"><span class="string">  // available, the policy for updates is such that unattended-upgrades</span></span><br><span class="line"><span class="string">  // should also install from here by default.</span></span><br><span class="line"><span class="string">  "${distro_id}ESMApps:${distro_codename}-apps-security";</span></span><br><span class="line"><span class="string">  "${distro_id}ESM:${distro_codename}-infra-security";</span></span><br><span class="line"><span class="string">  //"${distro_id}:${distro_codename}-updates";</span></span><br><span class="line"><span class="string">  //"${distro_id}:${distro_codename}-proposed";</span></span><br><span class="line"><span class="string">  //"${distro_id}:${distro_codename}-backports";</span></span><br><span class="line"><span class="string">};</span></span><br></pre></td></tr></tbody></table></figure><h3 id="啟用自動更新">啟用自動更新</h3><p><code>/etc/apt/apt.conf.d/20auto-upgrades</code> 設定檔控制系統自動更新的行為。</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">APT::Periodic::Update-Package-Lists "1";</span><br><span class="line">APT::Periodic::Unattended-Upgrade "1";</span><br><span class="line">APT::Periodic::AutocleanInternal "7";</span><br></pre></td></tr></tbody></table></figure><p>其中，“1” 表示啟用，要禁用則改為 “0”。</p><h3 id="測試自動更新">測試自動更新</h3><p>使用下列指令進行空轉測試：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo unattended-upgrades --dry-run -–debug</span><br></pre></td></tr></tbody></table></figure><p>會顯示類似下面的結果：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">... 前面省略</span><br><span class="line"></span><br><span class="line">adjusting candidate version: python3-zope.interface=4.3.2-1build2</span><br><span class="line">pkgs that look like they should be upgraded: </span><br><span class="line">Fetched 0 B <span class="keyword">in</span> 0s</span><br><span class="line">fetch.run() result: 0</span><br><span class="line">blacklist: []</span><br><span class="line">whitelist: []</span><br><span class="line">No packages found that can be upgraded unattended and no pending auto-removals</span><br></pre></td></tr></tbody></table></figure><h4 id="啟用防火牆">啟用防火牆</h4><p>不少雲端基礎服務商，如 DigitalOcean, 都有提供雲端防火牆，如果是多台主機的情況下，使用雲端防火牆比較方便。以本文的單一主機來說，直接使用 Ubuntu 內建的 ufw 來提供簡易主機防火牆。</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ufw allow 80</span><br><span class="line">ufw allow 443</span><br><span class="line">ufw allow ssh</span><br><span class="line">ufw <span class="built_in">enable</span></span><br></pre></td></tr></tbody></table></figure><p>其中，假如 SSH 服務的監聽埠不是預設的 22 的話，要把 <code>ssh</code> 改成對應的埠號。</p><p><em>注意：不開啟 NodeBB 的 4567, 這個只允許從本機 (localhost) 連線</em></p><h2 id="資料庫安裝-Redis">資料庫安裝 (Redis)</h2><p>直接安裝系統預設的 Redis 套件，使用下列指令安裝：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install -y redis-server</span><br></pre></td></tr></tbody></table></figure><p>安裝後，為了讓 Redis 服務開機時自動啟動需要執行下列指令：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl <span class="built_in">enable</span> redis.service</span><br></pre></td></tr></tbody></table></figure><p>Redis 是作為 NodeBB 的主資料庫，所以資料持久性 (persistence) 需要特別設定以減少系統不正常當機時資料遺失的風險。為了這個目的，啟用 Redis 的 append-only log，底下是 append-only log 以及幾個相關的設定值 (檔案 /etc/redis/redis.conf)：</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">daemonize yes</span><br><span class="line">supervised systemd</span><br><span class="line">requirepass dsfjklewreriier    # redis 客戶端連線密碼，請不要直接套用，讀者需自訂。</span><br><span class="line">appendonly yes</span><br></pre></td></tr></tbody></table></figure><p>讀者需要將設定項目改成對應的設定值。</p><p>設定修改完成後，使用下列指令重啟 Redis:</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl restart redis.service</span><br></pre></td></tr></tbody></table></figure><p>Redis 安裝可參考 <a href="https://www.itread01.com/content/1545078980.html" target="_blank" rel="noopener">如何在 Ubuntu 18.04 上安裝和配置 Redis</a> 。</p><h2 id="Web-安全憑證-Let’s-Encrypt">Web 安全憑證 (Let’s Encrypt)</h2><p>Web 伺服器憑證是伺服器域名的身分證明，需要向一個 CA 組織申請核發，Let’s Encrypt 是個免費且受歡迎的 CA。<br>由於 Let’s Encrypt 已經支援 wildcard 域名憑證，本文使用 DNS 認證機制來申請 wildcard 憑證。</p><p>參考下列文章安裝 certbot 進行申請憑證:</p><ul><li><p><a href="https://medium.com/@lakin.mohapatra/generate-lets-encrypt-free-wildcard-certificate-on-ubuntu-18-dcf26f458e13" target="_blank" rel="noopener">Install Let’s Encrypt Free SSL Wildcard Certificate on ubuntu 18</a></p></li><li><p><a href="https://guides.wp-bullet.com/lets-encrypt-wildcard-ssl-nginx-for-wordpress-ubuntu-18-04/" target="_blank" rel="noopener">Let’s Encrypt Wildcard SSL nginx for WordPress Ubuntu 18.04</a></p></li></ul><p>因為希望憑證同時支援裸域名 (<a href="http://developers.tw" target="_blank" rel="noopener">developers.tw</a>) 以及子域名 (*.developers.tw)，申請指令要稍微修改</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo certbot --server https://acme-v02.api.letsencrypt.org/directory -d *.developers.tw -d developers.tw --manual --preferred-challenges dns-01 certonly</span><br></pre></td></tr></tbody></table></figure><p>按照畫面指示新增指定名稱的 DNS TXT 紀錄並進行驗證，如通過憑證檔案位於 <code>/etc/letsencrpyt</code> 目錄。</p><h2 id="Web-服務-Nginx">Web 服務 (Nginx)</h2><p>Web 服務有下列目的：</p><ul><li>作為 NodeBB 負載均衡器 (load balancer)。</li><li>支援 TLS/SSL 網路加密結定。</li><li>服務 NodeBB 靜態檔案資源。</li></ul><p>#<a href="http://Developers.TW" target="_blank" rel="noopener">Developers.TW</a> 使用 Nginx 作為 web 服務軟體。</p><h3 id="安裝-Nginx-套件">安裝 Nginx 套件</h3><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install -y nginx</span><br></pre></td></tr></tbody></table></figure><h3 id="設定-Nginx">設定 Nginx</h3><p>本文的安裝，NodeBB 服務只接受本地 (127.0.0.1) 連線，監聽埠是 4567。底下將 Nginx 設為 NodeBB 服務的代理伺服器。</p><p>新增 <code>/etc/nginx/sites-available/developers.tw</code>，檔案內容如下：</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line">upstream backend {</span><br><span class="line">  server 127.0.0.1:4567;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">server {</span><br><span class="line">  listen 80;</span><br><span class="line"></span><br><span class="line">  access_log  off;</span><br><span class="line">  error_log   off;</span><br><span class="line"></span><br><span class="line">  server_name developers.tw www.developers.tw;</span><br><span class="line"></span><br><span class="line">  return 301 https://developers.tw$request_uri;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">server {</span><br><span class="line">  listen 443 ssl;</span><br><span class="line">  listen [::]:443 ssl;</span><br><span class="line"></span><br><span class="line">  access_log  off;</span><br><span class="line">  error_log   off;</span><br><span class="line"></span><br><span class="line">  server_name www.developers.tw;</span><br><span class="line"></span><br><span class="line">  ssl on;</span><br><span class="line">  ssl_certificate /etc/letsencrypt/live/developers.tw/fullchain.pem; # managed by Certbot</span><br><span class="line">  ssl_certificate_key /etc/letsencrypt/live/developers.tw/privkey.pem; # managed by Certbot</span><br><span class="line"></span><br><span class="line">  return 301 https://developers.tw$request_uri;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">server {</span><br><span class="line">  listen 443 ssl http2;</span><br><span class="line">  listen [::]:443 ssl http2;</span><br><span class="line"></span><br><span class="line">  error_log /var/log/nginx/developers.tw-error.log;</span><br><span class="line">  access_log /var/log/nginx/developers.tw-access.log;</span><br><span class="line"></span><br><span class="line">  server_name developers.tw;</span><br><span class="line"></span><br><span class="line">  root /opt/nodebb/public;</span><br><span class="line">  index index.html;</span><br><span class="line"></span><br><span class="line">  gzip            on;</span><br><span class="line">  gzip_min_length 1000;</span><br><span class="line">  gzip_proxied    off;</span><br><span class="line">  gzip_types      text/plain application/xml text/javascript application/javascript application/x-javascript text/css application/json;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  ssl on;</span><br><span class="line">  ssl_stapling on;</span><br><span class="line">  ssl_stapling_verify on;</span><br><span class="line">  ssl_certificate /etc/letsencrypt/live/developers.tw/fullchain.pem; # managed by Certbot</span><br><span class="line">  ssl_certificate_key /etc/letsencrypt/live/developers.tw/privkey.pem; # managed by Certbot</span><br><span class="line">  ssl_protocols TLSv1.1 TLSv1.2;</span><br><span class="line">  ssl_prefer_server_ciphers on;</span><br><span class="line">  ssl_ciphers "EECDH+AESGCM:EDH+AESGCM:AES256+EECDH:AES256+EDH";</span><br><span class="line">  ssl_session_cache shared:SSL:10m;</span><br><span class="line"></span><br><span class="line">  proxy_set_header X-Real-IP $remote_addr;</span><br><span class="line">  proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;</span><br><span class="line">  proxy_set_header X-Forwarded-Proto $scheme;</span><br><span class="line">  proxy_set_header Host $http_host;</span><br><span class="line">  proxy_set_header X-NginX-Proxy true;</span><br><span class="line"></span><br><span class="line">  proxy_redirect off;</span><br><span class="line"></span><br><span class="line">  # Socket.IO Support</span><br><span class="line">  proxy_http_version 1.1;</span><br><span class="line">  proxy_set_header Upgrade $http_upgrade;</span><br><span class="line">  proxy_set_header Connection "upgrade";</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  location @backend {</span><br><span class="line">        proxy_pass http://backend;</span><br><span class="line">  }</span><br><span class="line"></span><br><span class="line">  location ~ ^/assets/(.*) {</span><br><span class="line">    root /opt/nodebb/;</span><br><span class="line">    try_files /build/public/$1 /public/$1 @backend;</span><br><span class="line">  }</span><br><span class="line"></span><br><span class="line">  location /plugins/ {</span><br><span class="line">    root /opt/nodebb/build/public/;</span><br><span class="line">    try_files $uri @backend;</span><br><span class="line">  }</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">location / {</span><br><span class="line">  proxy_pass http://backend;</span><br><span class="line">}</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>同樣地，<code>developers.tw</code> 需要更換為論壇實際使用的域名。<br>除了來自 NodeBB 官方文件的建議設定外，也設定了強制將 <code>www.developers.tw</code> 轉址為 <code>developers.tw</code>，且 <code>http</code> 協定轉成 `https’，也就是說：只接受 HTTPS 連線。</p><h3 id="啟用-NodeBB-的站點">啟用 NodeBB 的站點</h3><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo ln -s /etc/nginx/sites-available/developers.tw /etc/nginx/sites-enabled/</span><br><span class="line">$ sudo nginx -t</span><br><span class="line">$ sudo systemctl restart nginx</span><br></pre></td></tr></tbody></table></figure><p>到這個步驟，沒問題的話可以使用瀏覽器連線到 <a href="https://developers.tw" target="_blank" rel="noopener">https://developers.tw</a> , 但因為後端的 NodeBB 還沒啟用，網頁會出現 503 錯誤。</p><h2 id="執行環境安裝-NodeJS">執行環境安裝 (NodeJS)</h2><p>NodeJS 以及 NodeBB 的安裝都是參考這篇文章 <a href="https://blog.nodebb.org/how-to-install-nodebb-on-digitalocean-ubuntu-18-04/" target="_blank" rel="noopener">How To: Install NodeBB on DigitalOcean/Ubuntu 18.04</a> 。</p><p>使用下列指令安裝 NodeJS：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo curl -sL https://deb.nodesource.com/setup_12.x | sudo -E bash -</span><br><span class="line">$ sudo apt update</span><br><span class="line">$ sudo apt install nodejs -y</span><br></pre></td></tr></tbody></table></figure><h2 id="應用服務安裝-NodeBB">應用服務安裝 (NodeBB)</h2><h3 id="新增-nodebb-帳戶">新增 nodebb 帳戶</h3><p>為了權限控管，NodeBB 服務使用 nodebb 帳戶執行。使用下列指令新增帳戶：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo adduser nodebb</span><br></pre></td></tr></tbody></table></figure><h3 id="複製-NodeBB-原始程式">複製 NodeBB 原始程式</h3><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /opt</span><br><span class="line">$ sudo git <span class="built_in">clone</span> https://github.com/NodeBB/NodeBB.git nodebb</span><br><span class="line">$ sudo chown -R nodebb:nodebb ./nodebb</span><br><span class="line">$ sudo su - nodebb</span><br></pre></td></tr></tbody></table></figure><h3 id="初始設定-NodeBB">初始設定 NodeBB</h3><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /opt/nodebb</span><br><span class="line">$ ./nodebb setup</span><br></pre></td></tr></tbody></table></figure><p><code>./nodebb setup</code> 會詢問一系列問題，除下列外其餘使用預設值：</p><table><thead><tr><th>項目</th><th>設定值</th></tr></thead><tbody><tr><td> url</td><td><a href="https://developers.tw" target="_blank" rel="noopener">https://developers.tw</a></td></tr><tr><td>database</td><td> 選擇 redis</td></tr><tr><td>redis password</td><td> 在<code>資料庫安裝 (Redis)</code> 章節中，<code>requirepass</code> 的設定值</td></tr></tbody></table><p><code>url</code> 需要根據實際的域名做修改，上面範例是 #<a href="http://Developers.TW" target="_blank" rel="noopener">Developers.TW</a> 的域名。</p><h3 id="讓-NodeBB-隨系統自動啟動">讓 NodeBB 隨系統自動啟動</h3><p>使用文字編輯器新增 / 修改檔案 <code>/etc/systemd/system/nodebb.service</code>，內容為：</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=NodeBB</span><br><span class="line">Documentation=https://docs.nodebb.org</span><br><span class="line">After=system.slice multi-user.target redis.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=forking</span><br><span class="line">User=nodebb</span><br><span class="line"></span><br><span class="line">StandardOutput=syslog</span><br><span class="line">StandardError=syslog</span><br><span class="line">SyslogIdentifier=nodebb</span><br><span class="line"></span><br><span class="line">WorkingDirectory=/opt/nodebb</span><br><span class="line">ExecStart=/usr/bin/node loader.js</span><br><span class="line">Restart=always</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl daemon-reload</span><br><span class="line">$ sudo systemctl enable nodebb.service</span><br><span class="line">$ sudo systemctl start nodebb.service</span><br></pre></td></tr></tbody></table></figure><p>啟動完成後，就可以開啟瀏覽器連到 <a href="https://developers.tw/admin" target="_blank" rel="noopener">https://developers.tw/admin</a> , 登入控制台進行 NodeBB 的管理與設定。</p><h2 id="小結">小結</h2><p>經過冗長的來來回回步驟後，終於有個可以上線的部署環境。但有了基本部署環境，NodeBB 還要根據需要進行設定與客製化，這個才是重中之重。NodeBB 的設定可以參考 <a href="https://docs.nodebb.org/" target="_blank" rel="noopener">官方的文件</a>，而 NodeBB 的進階功能，不少需要額外申請雲端服務 (如 Facebook SSO) 或者安裝軟體 (如 Solr 等)，讀者可視目的來決定是否有需要。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文山姆鍋分享如何安裝與設定一個 NodeBB 論壇的正式生產環境 (production environment)。由於整個環境不只包含 NodeBB 本身，會從主機系統的開始設定開始到 Nginx web 服務。安裝過程參考了多篇文章，對於特定元件的安裝細節會直接連結到對應的教學文章，本文盡量只做重點說明。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Ubuntu" scheme="https://samkuo.me/tag/ubuntu/"/>
    
      <category term="nodebb" scheme="https://samkuo.me/tag/nodebb/"/>
    
      <category term="digitalocean" scheme="https://samkuo.me/tag/digitalocean/"/>
    
      <category term="redis" scheme="https://samkuo.me/tag/redis/"/>
    
      <category term="nodejs" scheme="https://samkuo.me/tag/nodejs/"/>
    
      <category term="iframely" scheme="https://samkuo.me/tag/iframely/"/>
    
      <category term="solr" scheme="https://samkuo.me/tag/solr/"/>
    
  </entry>
  
  <entry>
    <title>社群論壇軟體 NodeBB</title>
    <link href="https://samkuo.me/post/2020/03/morden-web-forum-nodebb/"/>
    <id>https://samkuo.me/post/2020/03/morden-web-forum-nodebb/</id>
    <published>2020-03-20T03:04:45.000Z</published>
    <updated>2020-03-20T06:33:10.464Z</updated>
    
    <content type="html"><![CDATA[<p>最近山姆鍋在建置業餘專案 <a href="https://developers.tw" target="_blank" rel="noopener">#呆丸開發者</a>時，需要一個可以支援多對多溝通模式的 web 應用。幾經思考，覺得論壇軟體可以符合大部分需求。傳統的 web 論壇軟體雖然成熟，功能也完整，但網站需要符合 Mobile-first 的要求以及現代化的使用者體驗，所以需要跳脫傳統論壇軟體框架的選擇。可能合用且比較常見的有下列三個：<a href="https://www.discourse.org/" target="_blank" rel="noopener">Discourse</a>、<a href="https://nodebb.org/" target="_blank" rel="noopener">NodeBB</a> 以及 <a href="https://flarum.org/" target="_blank" rel="noopener">Flarum</a>。本文並非三者的優缺點比較，僅是山姆鍋介紹 NodeBB 的哪些特點，讓它成為最後選擇。</p><a id="more"></a><h2 id="NodeBB-簡介">NodeBB 簡介</h2><p>NodeBB 是基於 NodeJS 環境，支援 Redis 或 MongoDB 多種資料庫的現代化論壇軟體，透過 <a href="http://socket.io" target="_blank" rel="noopener">socket.io</a>(websocket 或者 long polling) 支援雙向即時溝通機制，提供使用者流暢的訊息流。(全是技術用語，山姆鍋果然是很糟的產品行銷人員 :D)</p><h2 id="選擇-NodeBB-的原因">選擇 NodeBB 的原因</h2><p>概略的 Google 比較後，大部分的人可能跟山姆鍋一樣會傾向於使用 Discourse，畢竟從社群大小、功能、畫面等等，Discourse 是這三者最優。一開始，山姆鍋也是從 Discourse 開始試用，但當自己開始實際安裝後就開始撞牆了，再經過幾次不成功的嘗試後 (官網的安裝步驟、DigitalOcean 的一鍵安裝等等)，對於自行安裝維運 Discourse 的信心直線下降。轉而試圖安裝 NodeBB, 按照官方文件沒有困難地就完成安裝與基本設定，當然正式生產環境還必須要有主機安全加強、HTTPS 連線等，山姆鍋有時間再分享如何完成 NodeBB 的生產環境設定。話說 Flarum 的社群更小，開發進度緩慢，況且山姆鍋有可能需要對網站進行功能擴充，但不想再學習 PHP，所以連試用它的機會都沒有。Flarum 可謂不戰之罪，偏好 PHP 執行環境的人，可以評估一下 Flarum 是否符合需求。</p><p>簡單地歸納，山姆鍋會選擇 NodeBB 的原因有下列幾點：</p><h3 id="容易安裝">容易安裝</h3><p>根據山姆鍋過去的經驗，Flarum 應該更好安裝與設定，但因為上述原因被排除了。跟 Discourse 比起來，NodeBB 的安裝簡單的多，由於是自己維運這點就很重要。如果是使用雲端託管服務，雖然這點就變得不是那麼絕對，但反而費用會變成主要考量。</p><h3 id="系統要求低">系統要求低</h3><p>由於 #<a href="http://Developers.TW" target="_blank" rel="noopener">Developers.TW</a> 是個人業餘項目，自然希望花在主機等維運費用越低越好，目標是初期可以在 DigitalOcean 的最小 Droplet 上執行 (1 core, 1GB, 每月 $5&nbsp;元)，之後再根據需要擴充。這個規格根據 Discourse 官方資料看來是不實際的。對於一個可能沒有人使用的網站，即使是每個月 $5 也是額外的負擔，畢竟是業餘興趣，能省則省。</p><h3 id="容易擴充">容易擴充</h3><p>並不是說 Discourse 或者 Flarum 不容易擴充 (山姆鍋對兩者沒有深入研究)，而是山姆鍋已經決定縮小自己的主要程式語言為 JavaScript 跟 Python, 因為 NodeBB 採用 NodeJS 且支援外掛 (plug-in) 方式擴充功能，需要的話山姆鍋可以自行開發。所以，三者中山姆鍋自然是偏向 NodeBB。</p><h2 id="NodeBB-的特點">NodeBB 的特點</h2><h3 id="有商業支援">有商業支援</h3><p>以開源軟體的成熟度指標，有商業支援通常是一個很好的判斷依據。NodeBB 背後有 NodeBB Inc. 這家加拿大公司負責主要開發跟推廣，公司感覺不大，但既然核心團隊對於自己的產品有信心商業化，對使用者來說應該也算是一種保證。</p><h3 id="相對輕量化">相對輕量化</h3><p>最精簡的安裝的話，執行 NodeBB 只需要 NodeJS 以及 Redis 服務，對於記憶體以及 CPU 運算能力需求比 Discourse 低。 NodeJS 進程負責主程式，Redis 負責資料以及快取的用途，不過正式生產環境還需要在 NodeBB 主程式之前設置 web 伺服器 (建議 Nginx) 來負責靜態檔案以及 SSL 連線。</p><h3 id="支援-NoSQL">支援 NoSQL</h3><p>NodeBB 支援 Redis 或 MongosDB 作為論壇主資料庫這點，其中山姆鍋最關注的是 Redis 的支援。一般 Redis 被用來作為資料快取或者 Pub-sub 模式的訊息傳輸用途，當做主資料庫這點相當少見。由於 #<a href="http://Developers.TW" target="_blank" rel="noopener">Developers.TW</a> 算是很小的論壇網站，資料量跟使用者不多的情況下，使用 Redis 來存放資料可以有效提升網站存取效率。如果是中大型論壇，則建議採用 MongosDB + Redis 模式。</p><h3 id="支援外掛-plug-in">支援外掛 (plug-in)</h3><p>藉由外掛，第三方開發人員可以在不動到核心的情況下擴充軟體功能，這點跟 WordPress 跟 Drupal 的外掛相同。比較不同的是，為了提供前端網頁優化，外掛的啟用通常需要進行重新建置網頁並重啟服務才能生效，這點應該是開發團隊基於網頁效能的取捨，犧牲部署便利性換取應用執行效能。</p><h2 id="NodeBB-的缺點">NodeBB 的缺點</h2><p>建置 #<a href="http://Developers.TW" target="_blank" rel="noopener">Developers.TW</a> 到目前為止，也發現 NodeBB 的一些問題或者缺點，底下是山姆鍋比較在意的：</p><h3 id="社群比較小">社群比較小</h3><p>因為使用者基礎較少，遇到問題有較高的機會在 NodeBB 社群論壇找不到已有的解答。對於山姆鍋這種懶得發問的人算是小小的困擾。</p><h3 id="繁體中文翻譯不全">繁體中文翻譯不全</h3><p>雖然 NodeBB 也支援簡體跟繁體中文語系，但繁體中文的翻譯明顯年久失修，猜測原因應該是台灣使用 NodeBB 的人不多。由於簡體中文的翻譯相當完整，山姆鍋偷雞直接把簡體中文翻譯改成台灣習慣的用語並提交給 NodeBB 開發團隊。</p><h3 id="中文搜尋支援不佳">中文搜尋支援不佳</h3><p>NodeDB 官方的 dbsearch 外掛只能有效支援拉丁語系，像中文的機緣基本上完全無法使用。按照目前已知的資訊，官方有另一個使用 Solr 的搜尋外掛可以解決，但需要另外安裝 Solr 服務。由於不想耗用太多系統資源，山姆鍋選擇關閉搜尋功能，並沒有安裝 Solr, 所以尚無法證實 Solr 外掛的中文支援是否良好。</p><h3 id="有明顯的錯誤跟問題">有明顯的錯誤跟問題</h3><p>到目前為止，遇到下列幾個明顯但不嚴重的問題，</p><ul><li>使用者介面有未本地化的字串，加上中文搜尋的問題，NodeBB 的國際化 (i18n) 還需要加強。</li><li>使用者介面有幾個小錯誤，例如：版面 (category) 建立後，因為無法搜尋到其它版面資料導致無法更改版面的上層版面。</li></ul><h2 id="小結">小結</h2><p>NodeBB 是一個比較符合現代使用者體驗又不耗用太多系統資源的網路論壇，對於想要使用 Discourse 但卻無能力自行安裝的人或者不需要那麼多功能的人，山姆鍋現階段會建議使用 NodeBB。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近山姆鍋在建置業餘專案 &lt;a href=&quot;https://developers.tw&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;#呆丸開發者&lt;/a&gt;時，需要一個可以支援多對多溝通模式的 web 應用。幾經思考，覺得論壇軟體可以符合大部分需求。傳統的 web 論壇軟體雖然成熟，功能也完整，但網站需要符合 Mobile-first 的要求以及現代化的使用者體驗，所以需要跳脫傳統論壇軟體框架的選擇。可能合用且比較常見的有下列三個：&lt;a href=&quot;https://www.discourse.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Discourse&lt;/a&gt;、&lt;a href=&quot;https://nodebb.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;NodeBB&lt;/a&gt; 以及 &lt;a href=&quot;https://flarum.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Flarum&lt;/a&gt;。本文並非三者的優缺點比較，僅是山姆鍋介紹 NodeBB 的哪些特點，讓它成為最後選擇。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="nodebb" scheme="https://samkuo.me/tag/nodebb/"/>
    
      <category term="redis" scheme="https://samkuo.me/tag/redis/"/>
    
      <category term="forum" scheme="https://samkuo.me/tag/forum/"/>
    
      <category term="mongosdb" scheme="https://samkuo.me/tag/mongosdb/"/>
    
  </entry>
  
  <entry>
    <title>我為何選擇新創公司工作？</title>
    <link href="https://samkuo.me/post/2020/03/why-i-work-for-startups/"/>
    <id>https://samkuo.me/post/2020/03/why-i-work-for-startups/</id>
    <published>2020-03-05T02:59:33.000Z</published>
    <updated>2020-05-03T21:38:22.958Z</updated>
    
    <content type="html"><![CDATA[<!-- excerpt --><p>山姆鍋出社會後第一份工作剛好是 2000 年網際網路創業最火熱的時候，但這非山姆鍋選擇加入網際網路新創公司的主因。加入有制度的大公司或者新創事業的原因，追根究底真正的緣由都只是個人的追求不同。</p><h2 id="熱情是強大的自我驅動力">熱情是強大的自我驅動力</h2><p>說起山姆鍋會跟 IT 結緣的起因其實有點瞎，單單因為國中英文課本中出現 Computer (電腦) 這個名詞。在當時山姆鍋可從來沒看過實體的電腦長怎麼樣子，連電腦能做什麼等等都沒什麼概念。出於好奇心使然便到圖書館跟書店找相關的書籍，這下子電腦的無限可能性吸引我這個宅男一頭栽進學習資訊科技的不歸路。之所以提到這點，只是要點出山姆鍋的 IT 之路，從一開始就是由「覺得有趣」這個想法所驅動。因為覺得有趣所以就會自發地去學習跟了解相關的知識跟技能，而新的知識跟技能觸發更多的未知跟可能性，進而引發更大的興趣，所謂「熱情」應該不外乎就是這麼回事吧！</p><h2 id="能力來自於不斷地學習">能力來自於不斷地學習</h2><p>自從山姆鍋沈迷於資訊技術後，便開始學習相關的知識跟實作練習。由於對未來的工作還沒有具體的想像，所以不管是程式語言、資料庫、作業系統、人工智慧不同的主題，只要自己覺得那個語言或者技術很酷，就會花時間學習跟了解。回頭來看，其實這樣的學習方式的薪資回報率很差，但誰在乎？！對山姆鍋來說，學習 IT 新知就是一種休閒，才不是因為工作需要。曾經有非 IT 相關行業的朋友問山姆鍋：「你上班需要學電腦，為什麼下班還在看 IT 相關的東西」? 因為 IT 書籍對山姆鍋而言就跟其他人休閒時看八卦雜誌同樣的效果吧！<br>除非您像山姆鍋一樣把學習 IT 當休閒活動，不然真不建議您使用同樣的方式。這種方式會讓您學到工作上用不到的知識，例如下面是山姆鍋學過的程式語言：</p><ul><li>Basic (從早期 GW Basic 到 Visual Basic 好幾種)</li><li>DBase III (號稱第四代程式語言，包含資料庫)</li><li>C</li><li>C++</li><li>Pascal</li><li>Fortran</li><li>Cobol</li><li>Prolog</li><li>Scheme</li><li>Ada</li><li>Java</li><li>x86 Assembly</li><li>8051 Assembly</li><li>Go</li><li>C#</li><li>JavaScript</li><li>SQL</li></ul><p>還有幾個想不起來了，熟悉層度不一，但真正有用到的不到一半，常用的更不到三分之一。對了，您也許心裡會想：山姆鍋為什麼特地列出這麼多程式語言？沒錯，山姆鍋就是特地顯擺一下當年追過的程式語言。</p><p>遑論方法有沒有效率，對於山姆鍋這樣天資不算特優的人來說，由於比多數人更早起步，在 IT 這條路上，依然是其他人常常諮詢的對象，不管在學生時期還是出社會工作後。山姆鍋相信不管從事工作或創業，「不斷學習」絕對是提升個人能力的不二法門。</p><h2 id="能力就是要被看見">能力就是要被看見</h2><p>在山姆鍋大學時期的主修是資訊科技，而台灣 IT 科系畢業的學長姐大部分都往半導體、網通設備這類的 “硬體” 公司就業。雖然就產品而言，軟硬體同樣重要，但山姆鍋就是不爽從消費者的眼光只看得到硬體的產品。所以，做硬體產品相關的公司就被山姆鍋排除了；也就是說，在台灣 IT 以硬體為重心的國家，硬體公司就已經不在我的主要選項。請不要誤會，山姆鍋一開始也像多數人一樣想要進大公司，尋求一個穩定的工作，畢竟父母從小就是這麼教的。但幾次不愉快的面試經驗，讓山姆鍋放棄那些只會按照學歷跟資歷來決定薪資的公司，如果又是大公司，山姆鍋的能力要能被看見進而提高收入的機會實在太低了！</p><p>基於對自己技術的自信或者說不自信，新創公司是讓自己能力更有機會被看見的選擇。有制度跟前景的大公司必然也會吸引有能力的人，進入一家這樣的公司，除非天縱英才或有特殊背景，不然要升遷加薪難度頗高。就算是一開始就薪資豐厚，在大公司應該也沒有多少機會歷練不同職務。不管正確與否，就是這樣的想法讓山姆鍋決定加入讓自己能力比較容易被看到的新創公司。</p><h2 id="有趣又高薪的工作">有趣又高薪的工作</h2><p>由於網路的應用服務基本上就是軟體為重，加上大學時有自行使用 Apache + MySQL + PHP 開發網站的經驗，對於這種可以透過網路接觸龐大使用者的軟體深深地覺得潛 (錢) 力無限。可以說是自然而然，或者說是因緣際會，從第一家「資迅人」公司開始，都是從事網際網路應用服務相關的工作。相對於大公司而言，新創公司為了要找的適當的人，薪資通常會明顯比較高（雖然股票選擇權常常是打水漂），而對於山姆鍋這種背負學貸又要奉養父母的人來說，月薪高這點很重要 (薪水跟產業以及職位有直接關係，這裡高薪是相對於台灣平均薪資)。這裡山姆鍋所要表達的重點是：「您不需要為了高薪選擇無趣的工作，或者為了有趣而放棄高薪」。山姆鍋是全都要，小孩才做選擇 :-)</p><p>雖然「資迅人」因為網際網路 2000 年泡沫化而結束，第一份工作未滿一年就被迫轉換跑道，但從沒有因為這樣有過想找穩定工作的念頭 (除了結婚一開始有小孩的時候曾短暫去大公司上班，但更證實自己實在不喜歡大公司制度跟工作氛圍)。</p><h2 id="沒有穩定的工作">沒有穩定的工作</h2><p>有一次剛到職不到一個月的同事提辭呈，理由是父母要她到中 x 電信公司上班，因為哪裡的工作比較「穩定」。到底什麼是「穩定的工作」，每個人的定義也許或多或少不一樣，這裏山姆鍋就假設所謂「穩定的工作」就是一家有制度、賺錢的大公司所提供的工作機會。因為有制度，所以知道工作幾年薪資跟職位大概可以提升多少；因為賺錢不怕公司倒閉。但這樣的想法是工業時代思維，進入資訊時代的現在，這樣的說法雖然成立但並不完全。不要忘記：一家持續賺錢的公司，職務數量也許是相對穩定的，但擔任該職務的人不是，台灣可沒有所謂終身雇用制。對於個人來說，如果只是追求穩定安全的工作，不知道不斷學習進步，以為只要找到一份穩定的工作就可以高枕無憂都要小心被淘汰。所以山姆鍋認為：工作既然是依賴他人給予，既沒有法律保障，穩定的工作這種說法並不成立。</p><h2 id="工作需要熱情">工作需要熱情</h2><p>山姆鍋的個性對於不感到興趣的工作，自己的表現一定是平庸，畢竟山姆鍋只是比別人花更多時間，並非更有能力。山姆鍋討厭平庸也為了高薪，所以只好選擇有趣跟高薪的工作。也許有人會說：「我對現在的工作沒有熱情，下班之後就不會想工作上的事情，工作表現也不差啊！」，山姆鍋則會說：「您對現在的工作沒有熱情都可以表現不差的話，想像一下有熱情的話會是什麼成就？」。所以當山姆鍋遇到說工作不需要熱情的人，心裡的 OS: 「對，只要您不跟我同一團隊」<br>]</p><h2 id="新創公司有很多問題">新創公司有很多問題</h2><p>不可諱言，新創公司比大公司有更多的問題需要解決。制度跟流程方面，大公司已經很完善，但新創公司可能沒有或尚在建立；新創公司人員編制不足，有些問題內部人員也不知道怎麼處理比較好。以軟體工程師舉例來說，遇到一個技術問題，整個團隊沒有人會，通常這並不是大問題，反正大部分常見問題谷歌大神都可以得到解答。但產品核心技術一定要有人懂，或者您就是哪個懂的人，不然的話這樣的新創公司並不值得期待。</p><p>回應到在新創公司個人能力比較容易被看見這點，就是因為新創有更多各種大大小小的問題，而這些問題就是需要人解決。但如果有件事不知道該由誰處理或沒有人知道怎麼處理的時候，新創團隊就可以看出兩者心態，第一種：我只要負責做好我的事情，這件事情讓主管去想辦法；第二種：這件事我知道怎麼解決，或者可以研究怎麼解決。由於山姆鍋相對來說屬於第二種心態，所以團隊裡沒有人會做或者不願意做的事情就會落在山姆鍋身上。當公司對您的依賴越深，您的話語權就越高，薪資自然容易提升。這裏的依賴並不是指那些掌握某個關鍵模組的開發工作但卻不願意讓團隊其他人了解內部如何運作，一個合格的技術主管很容易就可以處理這樣的人。</p><p>所以說：要不是新創公司有那麼多問題，怎麼會有機會讓別人看到您的價值？所謂：「寧為雞首，不為牛後」，大公司跟新創公司各有不同的優勢，但想要在公司裡發揮影響力解決更大的問題，創造更高價值，您要先成為團體的領導者。這個不用多說，在小公司是更容易實現的。</p><h2 id="要有股票選擇權">要有股票選擇權</h2><p>山姆鍋有位同學在竹科一家小型的內嵌裝置廠商擔任軟體工程師的工作，有次聚會說到他現在的工作薪資不錯，也可以學到很多新技術，但常常要加班很晚。當山姆鍋得知他老闆沒有提供股票或選擇權的時候，當場就唸他 (現在想想自己太直接了，也許他有其它考量，這裡就先假設沒有)。山姆鍋的見解是：同樣是常加班、同樣薪資，也可以學到新技術，為什麼不到竹科其它做同樣產品但有選擇權的小公司？畢竟不管正職 (full-time) 或者兼職 (part-time)，作為員工都只是在打工，擁有公司的股票或選擇權才能讓員工的利益跟公司的成長一致。</p><p>在開始工作的前幾年，山姆鍋會因為聽到某某公司上市或上櫃，員工股票有幾百萬台幣獲利時常常羨慕不已，那時候還很天真，想說這樣不就可以退休？現在當然知道不夠。雖然非核心成員的員工，不會因為區區幾百萬而可以退休，但至少可以加速進程。因為擁有股票選擇權而想依賴公司上市達到財富自由，跟期望中樂透退休差不多，都可以洗洗睡了。作為員工，比較好的策略是從每個月相對高的薪資，提撥足夠的錢進行投資，雖然慢，但卻是成功率高的作法。如果運氣好，公司上市正好可以提早幾年達標。</p><p>雖說新創公司往往會提供股票選擇權，但不要因為這樣就接受比較低的薪資 (除非你是創辦人)。股票選擇權相當於是您在新創公司工作，因為工作不穩定所負擔的額外風險所做的補償。記住一句話：當您負擔額外風險，您就應該得到補償。這是市場基本運作原理之一。</p><h2 id="結語">結語</h2><p>雖然山姆鍋說要有趣且高薪的工作，但幫別人打工，只是一種賺錢的手段，並不是目的。不管您選擇打工或者創業的方式賺錢，越早學習跟懂得投資理財才能越早實現財富自由 (山姆鍋很希望自己能夠早知道這點)。自由代表擁有選擇權，同樣地：財富自由讓我們可以選擇不再只為了錢工作。所以，對於自己付出才能卻無法給予高薪 (或股票選擇權) 的工作，不如趁早換掉。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;山姆鍋出社會後第一份工作剛好是 2000 年網際網路創業最火熱的時候，但這非山姆鍋選擇加入網際網路新創公司的主因。加入有制度的大公司或者新創事業的原因，追根究底真正的緣由都只是個人的追求不同。本文山姆鍋也來分享當初選擇新創事業的因緣。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="startup" scheme="https://samkuo.me/tag/startup/"/>
    
      <category term="新創事業" scheme="https://samkuo.me/tag/%E6%96%B0%E5%89%B5%E4%BA%8B%E6%A5%AD/"/>
    
  </entry>
  
  <entry>
    <title>改用 Hexo 寫部落格文章</title>
    <link href="https://samkuo.me/post/2018/08/use-hexo-for-blog/"/>
    <id>https://samkuo.me/post/2018/08/use-hexo-for-blog/</id>
    <published>2018-08-30T15:29:50.000Z</published>
    <updated>2020-03-05T02:46:32.018Z</updated>
    
    <content type="html"><![CDATA[<!-- excerpt --><div class="figure " style="width:;"><img class="fig-img" src="pexels-photo-459688.jpeg" alt=""></div><p>折騰了將近 2 週將「我是山姆鍋」這個部落格改用 <a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a> 來編輯，雖然還是有不少文章格式有問題，大致上該有的都有了。</p><h2 id="為什麼要換成-Hexo">為什麼要換成 Hexo?</h2><p>最近好不容易動了更新部落格的想法，但對於原先使用的 Pelican 已經變得不太熟悉，在重新學習 Pelican 與新的工具之間，山姆鍋自然是喜新厭舊地選擇另一套工具啦！(不過可不希望以後再來一次，中間曾一度想放棄)。</p><h2 id="轉換文章格式">轉換文章格式</h2><p>Hexo 本身已經大致可以符合山姆鍋撰寫部落格的需要，再加上有相當豐富的插件做靠山，其它的需求自然沒什麼問題。山姆鍋的文章多數是以 <a href="https://zh.wikipedia.org/wiki/ReStructuredText" target="_blank" rel="noopener">reStructuredText</a> 格式撰寫，使用 Pandoc 這個工具轉換成 Markdown 格式後，文字的排列上都出現問題，整個轉換過程大部分的時間其實都是在調整亂掉的文章。</p><h2 id="站內文章搜索功能">站內文章搜索功能</h2><p>再來是原先使用 Tipue 的站內文章搜尋的功能，Hexo 上已經有人提供方案。基本上就是使用 <code>hexo-generator-tipue-search-json</code> 這個插件產生 Tipue 所需的搜尋索引檔案，設定好 <a href="/search/">搜尋頁面</a> 就可以了。中間遇到 JQuery 跟 Tipue 版本相容性的問題，不過 Google 一下也不難找到解決辦法。</p><h2 id="更換-markdown-it-作為渲染-render-引擎">更換 markdown-it 作為渲染 (render) 引擎</h2><p>由於常需要使用頁尾標記 (footnotes)，將 Hexo 內建的 Markdown 渲染引擎改為 <a href="https://github.com/markdown-it/markdown-it" target="_blank" rel="noopener">markdown-it</a>。<br>除了 markdown-it 本身，下列是額外安裝的插件：</p><ul><li>markdown-it-abbr</li><li>markdown-it-checkbox</li><li>markdown-it-container</li><li>markdown-it-deflist</li><li>markdown-it-footnote</li><li>markdown-it-imsize</li><li>markdown-it-ins</li><li>markdown-it-mark</li><li>markdown-it-regexp</li><li>markdown-it-sub</li><li>markdown-it-sup</li></ul><h2 id="更換主題樣板">更換主題樣板</h2><p>山姆鍋覺得原先的樣板沒有什麼不好，只是懶得自己轉換。選擇了 <a href="https://github.com/LouisBarranqueiro/hexo-theme-tranquilpeak" target="_blank" rel="noopener">Tranquilpeak</a> 這個主題也只是因為最接近自己的偏好。</p><h2 id="英文跟中文中間留白">英文跟中文中間留白</h2><p>山姆鍋習慣中文與英文字中間有間隔，但有懶得自己手動加入空白字元，再加上也常常忘記，最好還是在產生網頁時能夠自動調整。不知道為何 Hexo 的 <code>auto_spacing</code> 設定沒有作用，或者很有可能是山姆鍋沒有正確設定。不管怎樣，後來是使用 Pangu 這個程式庫寫一個過濾器 (filter) 解決。 下面是該過濾器的程式碼：</p><figure class="highlight javascript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> pangu = <span class="built_in">require</span>(<span class="string">'pangu'</span>)</span><br><span class="line"></span><br><span class="line">hexo.extend.filter.register(<span class="string">'after_post_render'</span>, <span class="function"><span class="keyword">function</span>(<span class="params">data</span>) </span>{</span><br><span class="line">  data.title = pangu.spacing(data.title)</span><br><span class="line">  data.content = pangu.spacing(data.content)</span><br><span class="line">})</span><br></pre></td></tr></tbody></table></figure><h2 id="小結">小結</h2><p>如果說轉換過程中，山姆鍋有學到什麼的話，那就是：沒事別換工具處理已經解決的問題，那只是在做苦工啊！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;折騰了將近 2 週將「我是山姆鍋」這個部落格改用 &lt;a href=&quot;https://hexo.io&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt; 來編輯，雖然還是有不少文章格式有問題，大致上該有的都有了。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="hexo" scheme="https://samkuo.me/tag/hexo/"/>
    
      <category term="pelican" scheme="https://samkuo.me/tag/pelican/"/>
    
  </entry>
  
  <entry>
    <title>容器化應用持續交付</title>
    <link href="https://samkuo.me/post/2016/04/containerized-app-continuous-delivery/"/>
    <id>https://samkuo.me/post/2016/04/containerized-app-continuous-delivery/</id>
    <published>2016-04-18T07:45:00.000Z</published>
    <updated>2020-05-03T22:00:22.904Z</updated>
    
    <content type="html"><![CDATA[<!-- excerpt --><div class="figure " style="width:;"><img class="fig-img" src="continuous-delivery.jpg" alt=""></div><p>自從山姆鍋決定採用容器化技術作為應用部署的方案後，很多的細節需要設計跟決定，為了避免太專注細節， 決定先設計出計畫採用的持續軟體交付流程。由於每個團隊的使用的工具跟系統可能差異很大， 為了讓本文可以適用其他團隊，先以抽象流程來描述然後才說明山姆鍋採用的方案。</p><p>此流程在完成軟體持續整合、部署與交付所需要的支援。為了減低人為的錯誤以及強化軟體品質，軟體部署的流程需加以自動化且在其中加入自動功能測試的步驟。</p><h2 id="流程概觀">流程概觀</h2><p>整個流程故意以抽象的概念表示，並沒有提到具體使用的工具或系統，因為這些跟個別團隊有關。底下是流程步驟的簡短說明：</p><ol><li>開發人員提交程式碼到「源始碼儲存庫」後，「源始碼儲存庫」會透過 webhook 通知「持續整合系統 (CI)」有新的程式碼。</li><li>「持續整合系統」會啟動並排程軟體建置任務來完成取出源始碼、編譯、單元測試、包裝與整合測試。</li><li>「持續整合系統」將應用容器發佈到「容器映像儲存庫」。</li><li>「持續整合系統」通知「部署機器人」有新的應用容器發佈。</li><li>「部署機器人」會將發佈的應用容器自動部署到 「QA 環境」，容器映像是由部署環境直接由「容器映像儲存庫」下載到主機節點。</li></ol><p>有個系統沒有呈現在圖中，但卻扮演至關重要的角色：「群組訊息系統」，之所以沒有呈現出來是擔心圖形過於複雜，因為基本上，其它系統或工具都會跟它有互動。當「開發人員」將程式碼提交到「源始碼儲存庫」時，「源始碼儲存庫」便會通知相關群組此訊息，而「持續整合系統」在建置過程如有任何錯誤也會將此事件回報給相關群組成員，如果沒有問題則會通知容器發佈的消息。「自動部署機器人」會從「群組訊息系統」監聽容器發佈的消息，一旦有容器發佈會立刻自動將該容器部署到「QA 環境」。</p><p>幾個特別注意的事項：</p><ul><li>目前部署到「生產環境」須由維運人員指示「自動部署機器人」來執行，但部署的動作仍舊是自動完成。</li><li>容器映像的標籤 (tag)<br>需要能夠讓開發人員很容易回推當初建置該映像 (image) 所使用的程式碼版本跟分支。</li><li>根據部署環境的複雜度而定，「自動部署機器人」的功能也可以整合到「持續整合系統」中。</li></ul><p>了解了流程抽象概念後，後續小節說明具體使用的工具或系統。</p><h2 id="群組訊息系統">群組訊息系統</h2><p>這個系統是讓開發團隊內不同的群組 (groups) 可以即時的訊息溝通，而群組的成員並不限制只有人， 自動系統也會參與。因為需要整合自動化系統，使得常見的即時訊息服務，如 Line, QQ, Skype 等， 無法勝任這個角色。因此，有特別針對這個需要提供的雲端服務，目前主要的：Slack, HipChat, Gitter， 按照跟其它系統的整合支援度排序。</p><p>許多人會選擇 Slack，但因為有整合的考量，本團隊選擇使用同樣由 Atlassian 公司提供的 HipChat 服務。 群組訊息系統可以說是團隊的神經系統，讓團隊可以更快有效地彼此同步訊息，這對於像本團隊一樣， 成員分散在不同地區與工作時間的團隊尤其重要。另外，我們也改用此系統做 Scrum 的 standup 會議， 當然實際形式上有所不同。</p><h2 id="源始碼管理系統">源始碼管理系統</h2><p>以目前發展的態勢以及雲端服務的多寡來判斷，Git 作為源始碼管理系統的首選應該是大勢底定。 使用 Git 的主要原因：</p><ul><li>有成熟的雲端託管服務商 (GitHub, BitBucket, etc)。</li><li>快速方便的源始碼分支 (branch) 與合併 (merge) 功能。</li><li>可以離線提交 (commit)，避免一次性提交一大段難以理解的源始碼。</li><li>除了中央源始碼儲存庫外，開發者的本機也是源始碼的完整備份。</li></ul><h2 id="源始碼託管服務-源始碼儲存庫">源始碼託管服務 / 源始碼儲存庫</h2><p>主要的雲端源始碼託管服務有: GitHub, BitBucket，因為整體考量，本團隊採用 BitBucket 作為源始碼託管服務供應商。 不管採用哪種源始碼管理系統，交付流程都需要有一個中央源始碼儲存庫來存放平台所有源始碼，自動建置系統會從此儲存庫取出並建置要部署的軟體元件。使用源始碼託管服務還有個好處，就是可以很好地支援 Pull request，讓 code review 的流程更順暢。</p><h2 id="容器映像儲存庫-Image-Repository">容器映像儲存庫 (Image Repository)</h2><p>當採用以容器化 (containerized) 方式來發行軟體元件時，便需要一個容器映像儲存庫。此儲存庫， 顧名思義是用來存放打包好的應用程式或者服務模組。本團隊後端的服務或應用皆是以容器來包裝跟交付， 即使是前端開發人員，為了整合測試需要仍舊要對容器技術有基本的了解。目前雲端的容器映像儲存庫， 除了 Google Cloud Platform 跟 AWS 有提供外，另外兩個考慮的就是：</p><ul><li>Docker Hub</li><li><a href="http://Quay.io" target="_blank" rel="noopener">Quay.io</a></li></ul><p>本團隊目前採用的是 Docker Hub，原因無他，只是比較習慣而已。但未來如果需要更好的團隊權限控管與 HipChat 更好的整合，會考慮轉換為 <a href="http://Quay.io" target="_blank" rel="noopener">Quay.io</a>。</p><h2 id="自動建置系統-持續整合系統">自動建置系統 / 持續整合系統</h2><p>自動建置系統會在開發者提交源始碼後，自動 check out 源始碼並編譯、測試並產生二元檔案或者映像檔。軟體的部署只能使用由建置系統所產生的二元檔案或者映像檔，不能直接連上服務器進行修改動作。每個應用 / 元件 / 模組在自動建置階段需按照順序完成下列階段才算成功：</p><ol><li><dl><dt>單元測試 (unit test)</dt><dd> 元件需具備足夠的單元測試以確保功能正確並且避免 regression 的發生。每個語言的單元測試方法或框架也許不同，但基本概念是一樣的。</dd></dl></li><li><dl><dt>元件包裝 (packaging)</dt><dd> 經過單元測試後，元件需要包裝成可以發佈的二進位形式，以傳統 Java 應用為例，這可以是一個 Jar 或者 War 檔。以本團隊的作法，後端服務都是以 Docker 容器形式包裝。行動應用則是根據支援的平台有所不同，如 Android 的 apk 檔，iOS 的 ipa 檔。Webapp 則是以 tgz 格式發佈。</dd></dl></li><li><dl><dt>整合測試 (integration test)</dt><dd> 針對後端元件，整合測試需要在本地採用 docker-compose 部署一個測試環境後執行相關的自動測試。針對行動應用，這個階段需將應用發佈到「裝置測試系統」來以實際裝置執行自動測試。</dd></dl></li><li><dl><dt>元件發佈 (release)</dt><dd> 經過單元與整合測試後的元件，已經可以發佈。注意這裡「發佈」是指將包裝後的元件推送至「容器映像儲存庫」，並不表示發佈給終端用戶。</dd></dl></li><li><dl><dt>元件部署 (deployment)</dt><dd> 針對後端元件，「部署」代表將包裝好的元件上載到應用部署環境後設定並啟用。這裡的部署環境可能是開發或者 QA 環境。部署的方式是自動建置系統會向 “Operations” 這個 HipChat 聊天室發佈元件已經發佈的消息，然後部署機器人會接續後續部署工作。也就是說，部署的工作並不是整個在自動建置系統內完成。針對行動應用，「部署」意味著行動應用可以讓 QA 人員下載、安裝到手機或者平板來進行測試。針對這點，也有雲端服務來提供行動應用發佈以方便 QA 人員下載跟安裝。</dd></dl></li></ol><h2 id="自動部署機器人-DevOps-Bot">自動部署機器人 (DevOps Bot)</h2><p>由於本團隊採用 Kubernetes 作為應用部署平台，現有的「持續整合系統」對它的整合度不高， 加上考量到生產環境要支援人工審核部署的步驟，才有了這樣的設計。對於一般常見的部署環境， 自動部署也可以在「持續整合環境」中完成，不少服務也針對部署有特別的支援。 本團隊的「自動部署機器人」，英文叫 Sammy，中文叫「蝦米」，會監聽某個 HipChat 特定地聊天室 (Operations) 的訊息，「持續整合系統」在應用容器發佈成功後在此聊天室發佈訊息， Sammy 收到該訊息後便會自動進行部署。</p><p>在 「QA 環境」測試過沒問題的版本，會由管理人員下指令給 Sammy 來部署到「生產環境」。 使用機器人有另一個好處：由於不是透過 Webhook 來取得通知，Sammy 可以部署在防火牆後，實際上 Sammy 同樣以容器形式被部署在應用平台中。除了第一次啟動 (bootstrap) 需要手動外， Sammy 也可以用來部署自己新的版本。</p><h2 id="應用部署平台-Deployment-Platform">應用部署平台 (Deployment Platform)</h2><p>這個平台主要是針對後端服務跟網站，容器化的應用元件在生產與 QA 環境的需要跟開發階段在本機以及自動建置環境不同。 應用部署平台提供應用的高可用性、擴充性以及其它非功能面的需求。目前團隊是採用 Kubernetes 來管理應用部署平台。</p><p>在此部署平台可以同時有多個部署環境 (environments)，至少會有 QA 跟生產 (Production) 兩個環境。</p><ul><li>QA 環境：是用來驗證開發中的應用功能正確也用來驗證一些非功能需求。</li><li>生產環境：應用的正式執行環境，支援應用的可用性、動態擴充、服務發現與負載均衡等。</li></ul><p>目前 「QA 環境」與「生產環境」共用同一組基礎設施 (infrastructure)，這樣做的幾個理由：</p><ul><li>管理彈性，主機節點可以在不同環境間挪用或共用。</li><li>確保環境之間的相似性，不用因應不同環境有不同的部署方式。</li></ul><h2 id="平台基礎設施-infrastructure">平台基礎設施 (infrastructure)</h2><p>「應用部署平台」提供應用的部署環境，但畢竟它是由軟體組成，最終還是需要伺服器來執行。 透過 Kubernetes 應用部署平台理論上可以採用不同的雲端基礎設施服務，但本團隊實際使用的是 AWS。 經過評估後，以 CoreOS 提供的虛擬機映像為基礎，實現 Kubernetes 需要的環境。 採用 CoreOS 的理由：</p><ul><li>需要方便可以在本地測試：需要的話，開發跟運營人員可以在本機複製一個叢集 (cluster) 環境來測試。</li><li>有較多的文件跟支援：使用 Google Cloud Platform 的支援度最廣，但本團隊使用的是 AWS 。</li><li>可以跨不同的基礎設施：實務上可能不會用到，但不被綁住在特定供應商總是一件好事。</li></ul><p>山姆鍋希望基礎設施可以類似 AWS CloudFormation 一樣可以自動建立，但又不想被綁定在 CloudFormation。 評估過 Ansible, SaltStack 這類組態管理工具後，發現 Terraform 比較適合這個工作，目前正在研究中。</p><h2 id="小結">小結</h2><p>本文所提的流程是山姆鍋所屬團隊所採用，但仍在建置中的方案，目前主要是「自動部署機器人」跟「應用部署平台」 有技術上的瓶頸。要特別說明的是：本文假設採用微服務架構 (Microservices)， 每個應用容器都是可以獨立部署的單元，不管該容器是用來部署一個應用、微服務或者批次工作 (batch job)。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;自從山姆鍋決定採用容器化技術作為應用部署的方案後，很多的細節需要設計跟決定，為了避免太專注細節， 決定先設計出計畫採用的持續軟體交付流程。由於每個團隊的使用的工具跟系統可能差異很大， 為了讓本文可以適用其他團隊，先以抽象流程來描述然後才說明山姆鍋採用的方案。&lt;/p&gt;
    
    </summary>
    
    <content src="https://samkuo.me//media/shared/continuous-delivery.png" type="image" />
    
    
      <category term="Service Operations" scheme="https://samkuo.me/category/service-operations/"/>
    
    
      <category term="container" scheme="https://samkuo.me/tag/container/"/>
    
      <category term="Continuous integration" scheme="https://samkuo.me/tag/continuous-integration/"/>
    
      <category term="Continuous delivery" scheme="https://samkuo.me/tag/continuous-delivery/"/>
    
      <category term="Continuous deployment" scheme="https://samkuo.me/tag/continuous-deployment/"/>
    
  </entry>
  
  <entry>
    <title>Shippable CI 上 Docker-compose 的難題</title>
    <link href="https://samkuo.me/post/2016/04/shippable-ci-docker-compose/"/>
    <id>https://samkuo.me/post/2016/04/shippable-ci-docker-compose/</id>
    <published>2016-04-16T08:40:00.000Z</published>
    <updated>2018-08-29T12:19:36.961Z</updated>
    
    <content type="html"><![CDATA[<p>如同多數使用 Docker 容器來部署應用的團隊一樣，山姆鍋也使用 Docker-compose 啟動一組相關的容器來進行整合測試。這樣的測試會在開發者工作機以及持續整合主機上執行。 但是，如果您跟山姆鍋一樣使用 Shippable 這家 CI 服務的話，您可能同樣會遇到一些小麻煩。</p><a id="more"></a><p>雖說山姆鍋很推薦使用 Circle CI 的服務，可惜的是它尚不支援 BitBucket <sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup> 。回到現實是 Shppable 目前沒有支援在建構容器中 (build container) <sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup> 執行 docker-compose 的功能， 所以，只好自己想辦法安裝。</p><p>注意：本文使用的是 Shippable 的 Golang 建構容器，其它不知道有沒有同樣問題。</p><h2 id="安裝-docker-compose">安裝 docker-compose</h2><p>「這個會有多難？」，一開始山姆鍋是這樣想的。只要使用 <code>pip</code>，按照下列命令就可以安裝了:</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pip install docker-compose</span><br></pre></td></tr></tbody></table></figure><p>當然是要在 shippable.yml 中設定，細節請自行參考 <a href="http://docs.shippable.com/ci_configure/" target="_blank" rel="noopener">Shippable 的文件</a>。 實際執行建構後，會遇到第一個問題：pyconfig.h 找不到，無法編譯 PyYAML 套件。看來少了開發 Python 原生 (native) 套件的支持，問題不大。</p><h2 id="安裝-python-dev-系統套件">安裝 python-dev 系統套件</h2><p>為了能夠安裝 PyYAML Python 套件，需要安裝 python-dev 這個系統套件，使用下列指令安裝：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install python-dev</span><br></pre></td></tr></tbody></table></figure><p>再次執行建構發現，PyYAML 已經可以安裝，docker-compose 套件也同樣安裝正常了，應該沒有問題了吧？！ 正期待一切順利進行的時候又冒出了一個問題，翻譯成中文大意是：</p><blockquote><p>您的 Docker engine 的版本過舊，docker-compose 要求須使用 1.10<br>以後的版本。</p></blockquote><p>檢查 Shippable CI 使用的版本是 1.9.1， 升級 Shippable 的 Docker engine 是不用想，直覺就是安裝舊版的 docker-compose 來適配這個版本。 就這樣一直試到 docker-compose 1.5.2，才支援 Shippable CI 使用的 engine 版本 <sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup> 。 這樣總算沒問題了吧！對 Docker-compose 夠熟的讀者應該會發現一個問題：compose 1.5.2 只支援 v1 的語法，而使用新技術不落人後的山姆鍋自然是用 v2 來寫 docker-compose.yml。</p><h2 id="改用-docker-compose-yml-v1-語法">改用 docker-compose.yml v1 語法</h2><p>整個問題至此大致已算是解決，主要的折衷是只能使用 compose v1 的功能。由於 docker-compose 在開發流程中只用來部署開發與測試環境， v1 語法也足夠使用 (雖然有些彆扭)。最終安裝 Docker-compose<br>的指令會類似下面片段:</p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="string">sudo</span> <span class="string">apt-get</span> <span class="string">install</span> <span class="string">python-dev</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">sudo</span> <span class="string">pip</span> <span class="string">install</span> <span class="string">docker-compose==1.5.2</span></span><br></pre></td></tr></tbody></table></figure><h2 id="小結">小結</h2><p>雖然不是很理想，但暫時先採取折衷方案，等有時間再換到新的 CI 服務或者等 Shippable CI 改進。 山姆鍋的立場是很贊成持續整合與部署，所以，就算是手機應用同樣也是採用持續整合的開發流程。 另外，Docker 容器技術根本是給後端開發人員的禮物，請多多利用！</p><hr><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>因為也使用同一家公司的其它服務，如 Jira, Confluence, HipChat，為了整合性，只好使用 BitBucket。 <a href="#fnref1" class="footnote-backref">↩︎</a></p></li><li id="fn2" class="footnote-item"><p>每個建構工作 (build job) 都是在各自的容器內進行。 <a href="#fnref2" class="footnote-backref">↩︎</a></p></li><li id="fn3" class="footnote-item"><p>Docker-compose 1.6.x 的 release notes 說支援 1.9.1 以上的版本，但山姆鍋測試是不行。 <a href="#fnref3" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;如同多數使用 Docker 容器來部署應用的團隊一樣，山姆鍋也使用 Docker-compose 啟動一組相關的容器來進行整合測試。這樣的測試會在開發者工作機以及持續整合主機上執行。 但是，如果您跟山姆鍋一樣使用 Shippable 這家 CI 服務的話，您可能同樣會遇到一些小麻煩。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Software Development" scheme="https://samkuo.me/category/software-development/"/>
    
    
      <category term="Continuous integration" scheme="https://samkuo.me/tag/continuous-integration/"/>
    
      <category term="Shippable" scheme="https://samkuo.me/tag/shippable/"/>
    
      <category term="Docker Compose" scheme="https://samkuo.me/tag/docker-compose/"/>
    
      <category term="CI" scheme="https://samkuo.me/tag/ci/"/>
    
  </entry>
  
  <entry>
    <title>Docker + Golang = Awesome</title>
    <link href="https://samkuo.me/post/2016/04/docker-golang-awesome/"/>
    <id>https://samkuo.me/post/2016/04/docker-golang-awesome/</id>
    <published>2016-04-16T01:33:00.000Z</published>
    <updated>2018-08-29T11:38:00.751Z</updated>
    
    <content type="html"><![CDATA[<p>稍微瞭解 Docker 容器技術的人，應該都知道它提供一種可攜帶的 (portable) 的方式讓應用可以在不同環境部署。 應用所需的程式庫、系統套件都完整封裝在容器內避免了傳統部署所遇到的相依性的問題。 但許多的應用包裝成容器後，動則幾百到上千 MB 的大小，在山姆鍋的觀念裡，這可算不上 "可攜帶"！</p><a id="more"></a><h2 id="為什麼要在意容器大小？">為什麼要在意容器大小？</h2><p>山姆鍋在 <a href="/post/2015/09/tiny-docker-image-with-ubuntu-bash/">「建構一個與 Ubuntu 相容的小型 Docker 映像」</a> 這篇文章中，有提到一些想法，這裡再補充說明。雖然 Docker 的階層式 (layered) 映像檔可以讓我們只需要更新增加的檔案， 也就是說：使用相同基礎映像的容器可以共用大部分的資料，但我們也知道這個前提映像必須已經在本地的快取 (cache) 中，這個說法才成立。以下兩種情況，容器大小仍舊是有關係的：</p><ol><li><dl><dt>準備新的開發機</dt><dd>對於使用容器作為應用部署技術的團隊，每個新進人員開發用的工作機都需要下載一次。</dd></dl></li><li><dl><dt>部署新的雲端虛擬機</dt><dd>在這個強調伺服器可以根據需要彈性部署的時代，隨時會有舊的虛擬機除役，新的虛擬機參與的情況。</dd></dl></li></ol><p>由於決定使用雲端作為應用部署基礎架構，第二點可以說關係到新伺服器上線到可以提供服務時間延遲的多寡， 先不管這個時間延遲是多久，改善這個延遲便是本文的重點。</p><h2 id="Golang-能幫上什麼？">Golang 能幫上什麼？</h2><p>Golang 是目前山姆鍋開發後端服務的首選程式語言，但針對容器大小，跟 Golang 有什麼太大的關聯？ 雖說 Docker 理論上可以支援大部分 (假如不是全部) 的程式語言環境，但有些事情是要講天份的 (無誤。 Golang 的幾個特性，讓它能夠有效減少容器大小：</p><ul><li><dl><dt>Golang 程式能編譯成一個靜態執行檔</dt><dd>在微服務 (microservcies) 架構下，複雜點的程式了不起 10 幾 MB，簡單的 5MB 以內搞定。<br>但這不是最重要的，重要的是這個執行檔除了作業系統核心 (kernel) 外不相依於其它程式庫，<br>所以可以使用 scratch 作為基礎映像 <sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup> 。</dd></dl></li><li><dl><dt>Golang 自備完整網路服務的程式庫</dt><dd>對於大部分的網路服務而言，Golang 提供足夠的程式庫支援可以完成。<br>雖然不像其它語言如 Java, NodeJS, Python 一樣多，Golang<br>也有許多第三方的程式庫可以選擇。</dd></dl></li><li><dl><dt>Golang 的執行效能夠高</dt><dd>因為 Golang<br>執行檔本身執行效率就夠高，通常的情況下就不會再搭配其它像是 Nginx<br>這樣的 web server。 但這裡特別說明，跟 C/C++, Java 比起來，目前<br>Golang 程式平均來說還是慢點， 但應該可以預期這個差距會越來越小。</dd></dl></li></ul><h2 id="為什麼-Golang-需要-Docker">為什麼 Golang 需要 Docker?</h2><p>雖然 Golang 的幾個特性已經讓它很容易部署，但還是有幾個地方是它不太方便的地方。其中， 就以程式所需的靜態資源檔 (static resources) 的存取比較麻煩。靜態資源檔泛指程式除了程式碼外，<br>需要連同程式一起部署的設定檔、資料檔、HTML, 等等不一而足。雖然有方法可以將一些靜態檔案內嵌到執行檔中， 但在開發流程上總有些不方便，所以，除非必要，山姆鍋是不會想用這個方法的。幸好，目前 Golang 只使用在後端服務開發，部署上也要求一定要使用 Docker，把程式需要的資源檔一起放置在容器內的檔案系統， 只是小菜一碟。</p><h2 id="小結">小結</h2><p>微服務架構隨著 Docker 容器化技術的成熟，相信會有越來越多的公司採用。而 Golang 先天上的優勢， 使得它非常適合撰寫高併發的網路服務，這兩者的結合可以說是一種絕配，但青菜蘿蔔各有所好， 語言的選擇從來就不是一件簡單的事情！</p><hr><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>對於不熟 Docker 的人，可以把 scratch 想成是一個沒有任何資料的容器映像。 <a href="#fnref1" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;稍微瞭解 Docker 容器技術的人，應該都知道它提供一種可攜帶的 (portable) 的方式讓應用可以在不同環境部署。 應用所需的程式庫、系統套件都完整封裝在容器內避免了傳統部署所遇到的相依性的問題。 但許多的應用包裝成容器後，動則幾百到上千 MB 的大小，在山姆鍋的觀念裡，這可算不上 &quot;可攜帶&quot;！&lt;/p&gt;
    
    </summary>
    
    
      <category term="Service Operations" scheme="https://samkuo.me/category/service-operations/"/>
    
    
      <category term="container" scheme="https://samkuo.me/tag/container/"/>
    
      <category term="Docker" scheme="https://samkuo.me/tag/docker/"/>
    
      <category term="golang" scheme="https://samkuo.me/tag/golang/"/>
    
  </entry>
  
  <entry>
    <title>建立研發團隊比想像中的還要難 100 倍以上</title>
    <link href="https://samkuo.me/post/2016/03/new-development-team/"/>
    <id>https://samkuo.me/post/2016/03/new-development-team/</id>
    <published>2016-03-23T04:39:00.000Z</published>
    <updated>2018-08-29T15:50:46.112Z</updated>
    
    <content type="html"><![CDATA[<p>山姆鍋的「懶惰病」看來還蠻嚴重的，轉眼離上一篇文章已經是三個多月的事情了！雖然不是最久的紀錄，但這樣還蠻誇張的。這段時間山姆鍋在台北開始了新的工作， 莫名奇妙就在做手機軟體開發，沒多久卻「漂流」到新竹清大育成中心， 負責成立並管理一個研發團隊。</p><a id="more"></a><p>不管是不是計畫趕不上變化，話說成立這個研發團隊到底是為了什麼目的？ 山姆鍋就用面試時會回答的官方答案：「本團隊是以開發手遊加值的軟體與服務為主軸， 屬於公司內部創業，預期要成長茁壯為獨當一面的新創公司。」 既然是團隊，那團隊的任務就必須清楚才能讓成員知道方向。</p><h2 id="團隊任務">團隊任務</h2><p>此團隊目標在建立一個手遊影音分享平台，做到：</p><ul><li>讓同遊戲的玩家可以分享遊戲技巧與心得，不用再為卡關受苦。</li><li>遊戲開發者可以建立遊戲專屬頻道與其玩家互動，提高遊戲黏著度。</li><li>讓遊戲高手或主播可以建立節目 (直播或點播) 與粉絲分享，並創造營收。</li></ul><p>是的，我們知道已經有公司在做類似的服務，但就讓我們假設競爭是好事。</p><h2 id="關鍵技術">關鍵技術</h2><p>要完成最終的平台需要幾個關鍵技術，底下是山姆鍋歸納的結果：</p><ul><li>手遊畫面與聲音同步擷取後錄製與直播所需的 SDK。</li><li>手機端使用者介面 (webview-based) 提供玩家與社群的功能。</li><li>遊戲影音分享網站前端 (browser-based)：讓同遊戲的玩家可以分享遊戲技巧與討論心得等等。</li><li>遊戲影音分享網站後端：提供身份認證、視訊資料儲存、分佈與串流等功能。</li></ul><p>其中一個直播串流採用的技術是 HTTP Live Streaming，在之前的文章有分享過相關應用。</p><h2 id="召募對象">召募對象</h2><p>對於開發工程師，不管是在學生或者全職人員，山姆鍋的最基本的要求：</p><ul><li>對手機軟體開發有興趣</li><li>不怕技術挑戰</li><li>為了任務願意學習新東西</li></ul><p>山姆鍋認為一個人如果對於做的事情沒有興趣或者熱情，最好的情況下也只是有平庸的表現。 不管是基於對技術的熱情或者對高薪的追求，要從事軟體開發這種需要不斷學習的工作， 還真的要有內在動機才能堅持下去。</p><p>為什麼需要不怕技術挑戰？因為需要使用到手機平台比較底層的 API 才能實現相關的功能。 例如：要能夠達到至少每秒 30 張遊戲畫面擷取，還要同時做聲音輸入並錄製成影像檔。 這些都不是一般 App 開發會用到的，未來還有直播串流等相關要求，技術難度肯定是有的。</p><p>需要學習新東西這點基本上是廢話，但就是有人認為學校教的就夠了！ 我們歡迎沒有工作經驗的人加入，只要您夠聰明又願意學習。</p><h3 id="為什麼要使用-C">為什麼要使用 C++?</h3><p>在找 iOS/Android 開發工程師時常被問到：為什麼不是 Java 或者 Objective C， 而是要找熟悉 Ｃ＋＋ 的人？主要是基於下列原因：</p><ol><li>為了跨平台共用程式：是的，我們需要支援多個行動平台，iOS 跟 Android<br>是最主要的兩個。</li><li>為了執行效率：除了 C，我想不到其他主流語言比 C++ 快。</li><li>支援物件導向：比 C 提供更高階的抽象化來解決問題，比較好維護。</li><li>需要跟 Cocos2d-x 等遊戲引擎整合：這些引擎大多是以 C++ 開發。</li></ol><h3 id="為什麼一定要已經熟悉-C">為什麼一定要已經熟悉 C++?</h3><p>這是因為山姆鍋有個人偏見：認為 C++ 是主流程式語言裡面最難學會的。對於一個新創團隊來說， 訓練一個工程師從頭開始學 C++ 到上手，恐怕是不實際的期望。山姆鍋自己也還在持續學習 C++ 當中，有機會再來分享 C++ 跨手機平台開發 App 的經驗。 基於這個原因，已經熟悉 C++ 的高手自然就成為主要目標。這不代表說不需要會其它技能， 只是會 Java 或 Objective C，有開發過手機 app 這些都只是加分， 並不在山姆鍋找夥伴的必要條件中。</p><h3 id="為什麼要使用-MacBook-Pro-作為開發機？">為什麼要使用 MacBook Pro 作為開發機？</h3><p>山姆鍋思考事情通常都很務實，使用 MacBook 可不是因為有雅痞的 fu。理由是因為只有 Apple 的機器可以合法用來開發 iOS 相關軟體，想知道為什麼請去問 Apple 這家公司！ 用了好幾年 Ubuntu 的山姆鍋也只好轉到 OSX 的作業環境下。 不過老實講， MacBook 也沒什麼好抱怨，可以方便使用眾多的開源軟體又有良好的桌面整合環境。所以， 團隊成員以 MacBook Pro 作為主要開發機就這樣定案了。</p><h3 id="需要一定在辦公室工作嗎？">需要一定在辦公室工作嗎？</h3><p>這點因人而異，但基本上，每週還是需要有一定比例的時間在辦公室。隨著對團隊的工作流程更加熟悉， 加上本身夠自律，不用到辦公室的時間自然可以加長。</p><h2 id="小結">小結</h2><p>這段時間以來，雖然想過找人不容易，但還是比預期的困難許多，其中有些原因還是自作自受。 不管怎樣，山不轉路轉，暫時找不到適合的夥伴，那就將部分開發工作外包。在工作的時間跟地點， 山姆鍋的老闆願意支持可以有這麼高的彈性，這點在台灣應該也算是少見。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;山姆鍋的「懶惰病」看來還蠻嚴重的，轉眼離上一篇文章已經是三個多月的事情了！雖然不是最久的紀錄，但這樣還蠻誇張的。這段時間山姆鍋在台北開始了新的工作， 莫名奇妙就在做手機軟體開發，沒多久卻「漂流」到新竹清大育成中心， 負責成立並管理一個研發團隊。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Teamwork" scheme="https://samkuo.me/category/teamwork/"/>
    
    
      <category term="軟體工程師" scheme="https://samkuo.me/tag/%E8%BB%9F%E9%AB%94%E5%B7%A5%E7%A8%8B%E5%B8%AB/"/>
    
      <category term="實習生" scheme="https://samkuo.me/tag/%E5%AF%A6%E7%BF%92%E7%94%9F/"/>
    
  </entry>
  
</feed>
